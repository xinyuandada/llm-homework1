{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9229349330872173,
  "eval_steps": 500,
  "global_step": 6000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0015382248884786955,
      "grad_norm": 0.7800440192222595,
      "learning_rate": 9.995385325334565e-05,
      "loss": 3.3764,
      "step": 10
    },
    {
      "epoch": 0.003076449776957391,
      "grad_norm": 0.7170557975769043,
      "learning_rate": 9.990257909039636e-05,
      "loss": 3.2895,
      "step": 20
    },
    {
      "epoch": 0.0046146746654360865,
      "grad_norm": 0.7733101844787598,
      "learning_rate": 9.985130492744707e-05,
      "loss": 3.2437,
      "step": 30
    },
    {
      "epoch": 0.006152899553914782,
      "grad_norm": 1.1588221788406372,
      "learning_rate": 9.980003076449777e-05,
      "loss": 3.0131,
      "step": 40
    },
    {
      "epoch": 0.007691124442393478,
      "grad_norm": 1.1910779476165771,
      "learning_rate": 9.974875660154848e-05,
      "loss": 2.8109,
      "step": 50
    },
    {
      "epoch": 0.009229349330872173,
      "grad_norm": 0.9716565012931824,
      "learning_rate": 9.969748243859919e-05,
      "loss": 2.7559,
      "step": 60
    },
    {
      "epoch": 0.01076757421935087,
      "grad_norm": 1.3204234838485718,
      "learning_rate": 9.96462082756499e-05,
      "loss": 2.9574,
      "step": 70
    },
    {
      "epoch": 0.012305799107829564,
      "grad_norm": 1.1385749578475952,
      "learning_rate": 9.959493411270061e-05,
      "loss": 2.6185,
      "step": 80
    },
    {
      "epoch": 0.01384402399630826,
      "grad_norm": 1.5976508855819702,
      "learning_rate": 9.954365994975132e-05,
      "loss": 2.7861,
      "step": 90
    },
    {
      "epoch": 0.015382248884786957,
      "grad_norm": 1.2703982591629028,
      "learning_rate": 9.949238578680203e-05,
      "loss": 2.7095,
      "step": 100
    },
    {
      "epoch": 0.01692047377326565,
      "grad_norm": 0.9696293473243713,
      "learning_rate": 9.944111162385275e-05,
      "loss": 2.6845,
      "step": 110
    },
    {
      "epoch": 0.018458698661744346,
      "grad_norm": 1.0070174932479858,
      "learning_rate": 9.938983746090346e-05,
      "loss": 2.5992,
      "step": 120
    },
    {
      "epoch": 0.019996923550223044,
      "grad_norm": 0.7789586186408997,
      "learning_rate": 9.933856329795417e-05,
      "loss": 2.5619,
      "step": 130
    },
    {
      "epoch": 0.02153514843870174,
      "grad_norm": 0.9720857739448547,
      "learning_rate": 9.928728913500488e-05,
      "loss": 2.5737,
      "step": 140
    },
    {
      "epoch": 0.023073373327180433,
      "grad_norm": 0.9559718370437622,
      "learning_rate": 9.923601497205559e-05,
      "loss": 2.582,
      "step": 150
    },
    {
      "epoch": 0.024611598215659128,
      "grad_norm": 1.2294028997421265,
      "learning_rate": 9.91847408091063e-05,
      "loss": 2.5172,
      "step": 160
    },
    {
      "epoch": 0.026149823104137826,
      "grad_norm": 0.8206753730773926,
      "learning_rate": 9.9133466646157e-05,
      "loss": 2.6148,
      "step": 170
    },
    {
      "epoch": 0.02768804799261652,
      "grad_norm": 1.6609854698181152,
      "learning_rate": 9.908219248320772e-05,
      "loss": 2.5482,
      "step": 180
    },
    {
      "epoch": 0.029226272881095215,
      "grad_norm": 0.9564527869224548,
      "learning_rate": 9.903091832025842e-05,
      "loss": 2.5977,
      "step": 190
    },
    {
      "epoch": 0.030764497769573913,
      "grad_norm": 1.0379178524017334,
      "learning_rate": 9.897964415730913e-05,
      "loss": 2.6212,
      "step": 200
    },
    {
      "epoch": 0.032302722658052604,
      "grad_norm": 1.038809895515442,
      "learning_rate": 9.892836999435984e-05,
      "loss": 2.5757,
      "step": 210
    },
    {
      "epoch": 0.0338409475465313,
      "grad_norm": 1.1101423501968384,
      "learning_rate": 9.887709583141056e-05,
      "loss": 2.4347,
      "step": 220
    },
    {
      "epoch": 0.03537917243501,
      "grad_norm": 1.4410618543624878,
      "learning_rate": 9.882582166846127e-05,
      "loss": 2.451,
      "step": 230
    },
    {
      "epoch": 0.03691739732348869,
      "grad_norm": 1.5485572814941406,
      "learning_rate": 9.877454750551197e-05,
      "loss": 2.4091,
      "step": 240
    },
    {
      "epoch": 0.03845562221196739,
      "grad_norm": 0.8919523358345032,
      "learning_rate": 9.872327334256268e-05,
      "loss": 2.4517,
      "step": 250
    },
    {
      "epoch": 0.03999384710044609,
      "grad_norm": 1.5257225036621094,
      "learning_rate": 9.86719991796134e-05,
      "loss": 2.5079,
      "step": 260
    },
    {
      "epoch": 0.04153207198892478,
      "grad_norm": 1.1131129264831543,
      "learning_rate": 9.862072501666411e-05,
      "loss": 2.5233,
      "step": 270
    },
    {
      "epoch": 0.04307029687740348,
      "grad_norm": 1.0646756887435913,
      "learning_rate": 9.856945085371482e-05,
      "loss": 2.5011,
      "step": 280
    },
    {
      "epoch": 0.044608521765882175,
      "grad_norm": 0.9087584614753723,
      "learning_rate": 9.851817669076553e-05,
      "loss": 2.4325,
      "step": 290
    },
    {
      "epoch": 0.046146746654360866,
      "grad_norm": 0.9257020950317383,
      "learning_rate": 9.846690252781624e-05,
      "loss": 2.4766,
      "step": 300
    },
    {
      "epoch": 0.047684971542839565,
      "grad_norm": 1.2664592266082764,
      "learning_rate": 9.841562836486695e-05,
      "loss": 2.379,
      "step": 310
    },
    {
      "epoch": 0.049223196431318256,
      "grad_norm": 1.7497199773788452,
      "learning_rate": 9.836435420191767e-05,
      "loss": 2.497,
      "step": 320
    },
    {
      "epoch": 0.050761421319796954,
      "grad_norm": 1.0710874795913696,
      "learning_rate": 9.831308003896836e-05,
      "loss": 2.4277,
      "step": 330
    },
    {
      "epoch": 0.05229964620827565,
      "grad_norm": 1.1468404531478882,
      "learning_rate": 9.826180587601907e-05,
      "loss": 2.4062,
      "step": 340
    },
    {
      "epoch": 0.05383787109675434,
      "grad_norm": 0.9473360776901245,
      "learning_rate": 9.821053171306978e-05,
      "loss": 2.3603,
      "step": 350
    },
    {
      "epoch": 0.05537609598523304,
      "grad_norm": 0.9064487218856812,
      "learning_rate": 9.815925755012049e-05,
      "loss": 2.5071,
      "step": 360
    },
    {
      "epoch": 0.05691432087371174,
      "grad_norm": 1.2210891246795654,
      "learning_rate": 9.810798338717121e-05,
      "loss": 2.3493,
      "step": 370
    },
    {
      "epoch": 0.05845254576219043,
      "grad_norm": 1.030822992324829,
      "learning_rate": 9.805670922422192e-05,
      "loss": 2.5064,
      "step": 380
    },
    {
      "epoch": 0.05999077065066913,
      "grad_norm": 1.2741059064865112,
      "learning_rate": 9.800543506127263e-05,
      "loss": 2.4764,
      "step": 390
    },
    {
      "epoch": 0.06152899553914783,
      "grad_norm": 1.203805685043335,
      "learning_rate": 9.795416089832334e-05,
      "loss": 2.447,
      "step": 400
    },
    {
      "epoch": 0.06306722042762652,
      "grad_norm": 1.0742758512496948,
      "learning_rate": 9.790288673537404e-05,
      "loss": 2.427,
      "step": 410
    },
    {
      "epoch": 0.06460544531610521,
      "grad_norm": 1.02286958694458,
      "learning_rate": 9.785161257242476e-05,
      "loss": 2.4394,
      "step": 420
    },
    {
      "epoch": 0.06614367020458391,
      "grad_norm": 0.9090739488601685,
      "learning_rate": 9.780033840947547e-05,
      "loss": 2.4173,
      "step": 430
    },
    {
      "epoch": 0.0676818950930626,
      "grad_norm": 1.149408221244812,
      "learning_rate": 9.774906424652618e-05,
      "loss": 2.456,
      "step": 440
    },
    {
      "epoch": 0.0692201199815413,
      "grad_norm": 0.963049590587616,
      "learning_rate": 9.769779008357689e-05,
      "loss": 2.3834,
      "step": 450
    },
    {
      "epoch": 0.07075834487002,
      "grad_norm": 0.9821059107780457,
      "learning_rate": 9.76465159206276e-05,
      "loss": 2.4565,
      "step": 460
    },
    {
      "epoch": 0.0722965697584987,
      "grad_norm": 1.0546011924743652,
      "learning_rate": 9.759524175767832e-05,
      "loss": 2.396,
      "step": 470
    },
    {
      "epoch": 0.07383479464697738,
      "grad_norm": 1.0994268655776978,
      "learning_rate": 9.754396759472903e-05,
      "loss": 2.4549,
      "step": 480
    },
    {
      "epoch": 0.07537301953545608,
      "grad_norm": 0.8789143562316895,
      "learning_rate": 9.749269343177974e-05,
      "loss": 2.4605,
      "step": 490
    },
    {
      "epoch": 0.07691124442393478,
      "grad_norm": 0.9876823425292969,
      "learning_rate": 9.744141926883043e-05,
      "loss": 2.4503,
      "step": 500
    },
    {
      "epoch": 0.07844946931241348,
      "grad_norm": 1.1950620412826538,
      "learning_rate": 9.739014510588114e-05,
      "loss": 2.5059,
      "step": 510
    },
    {
      "epoch": 0.07998769420089218,
      "grad_norm": 1.1006996631622314,
      "learning_rate": 9.733887094293186e-05,
      "loss": 2.2882,
      "step": 520
    },
    {
      "epoch": 0.08152591908937086,
      "grad_norm": 0.9053552150726318,
      "learning_rate": 9.728759677998257e-05,
      "loss": 2.3396,
      "step": 530
    },
    {
      "epoch": 0.08306414397784956,
      "grad_norm": 1.1737337112426758,
      "learning_rate": 9.723632261703328e-05,
      "loss": 2.4247,
      "step": 540
    },
    {
      "epoch": 0.08460236886632826,
      "grad_norm": 0.8845342993736267,
      "learning_rate": 9.718504845408399e-05,
      "loss": 2.3835,
      "step": 550
    },
    {
      "epoch": 0.08614059375480695,
      "grad_norm": 1.0540077686309814,
      "learning_rate": 9.71337742911347e-05,
      "loss": 2.369,
      "step": 560
    },
    {
      "epoch": 0.08767881864328565,
      "grad_norm": 0.9919202923774719,
      "learning_rate": 9.708250012818541e-05,
      "loss": 2.4425,
      "step": 570
    },
    {
      "epoch": 0.08921704353176435,
      "grad_norm": 0.9196600914001465,
      "learning_rate": 9.703122596523612e-05,
      "loss": 2.3381,
      "step": 580
    },
    {
      "epoch": 0.09075526842024303,
      "grad_norm": 1.1251168251037598,
      "learning_rate": 9.697995180228683e-05,
      "loss": 2.3186,
      "step": 590
    },
    {
      "epoch": 0.09229349330872173,
      "grad_norm": 1.3643468618392944,
      "learning_rate": 9.692867763933754e-05,
      "loss": 2.4726,
      "step": 600
    },
    {
      "epoch": 0.09383171819720043,
      "grad_norm": 0.8772892951965332,
      "learning_rate": 9.687740347638825e-05,
      "loss": 2.4736,
      "step": 610
    },
    {
      "epoch": 0.09536994308567913,
      "grad_norm": 1.061119556427002,
      "learning_rate": 9.682612931343897e-05,
      "loss": 2.4213,
      "step": 620
    },
    {
      "epoch": 0.09690816797415783,
      "grad_norm": 0.9421314597129822,
      "learning_rate": 9.677485515048968e-05,
      "loss": 2.4277,
      "step": 630
    },
    {
      "epoch": 0.09844639286263651,
      "grad_norm": 1.2146601676940918,
      "learning_rate": 9.672358098754039e-05,
      "loss": 2.2897,
      "step": 640
    },
    {
      "epoch": 0.09998461775111521,
      "grad_norm": 1.2775753736495972,
      "learning_rate": 9.66723068245911e-05,
      "loss": 2.4684,
      "step": 650
    },
    {
      "epoch": 0.10152284263959391,
      "grad_norm": 1.0711489915847778,
      "learning_rate": 9.66210326616418e-05,
      "loss": 2.3954,
      "step": 660
    },
    {
      "epoch": 0.1030610675280726,
      "grad_norm": 0.9492761492729187,
      "learning_rate": 9.656975849869251e-05,
      "loss": 2.3824,
      "step": 670
    },
    {
      "epoch": 0.1045992924165513,
      "grad_norm": 0.8662605285644531,
      "learning_rate": 9.651848433574322e-05,
      "loss": 2.2737,
      "step": 680
    },
    {
      "epoch": 0.10613751730503,
      "grad_norm": 0.9089555740356445,
      "learning_rate": 9.646721017279393e-05,
      "loss": 2.4527,
      "step": 690
    },
    {
      "epoch": 0.10767574219350869,
      "grad_norm": 0.8828738331794739,
      "learning_rate": 9.641593600984464e-05,
      "loss": 2.3143,
      "step": 700
    },
    {
      "epoch": 0.10921396708198738,
      "grad_norm": 0.8621166944503784,
      "learning_rate": 9.636466184689535e-05,
      "loss": 2.2994,
      "step": 710
    },
    {
      "epoch": 0.11075219197046608,
      "grad_norm": 0.9188641309738159,
      "learning_rate": 9.631338768394606e-05,
      "loss": 2.3995,
      "step": 720
    },
    {
      "epoch": 0.11229041685894478,
      "grad_norm": 0.9558343291282654,
      "learning_rate": 9.626211352099678e-05,
      "loss": 2.3769,
      "step": 730
    },
    {
      "epoch": 0.11382864174742348,
      "grad_norm": 0.8890336751937866,
      "learning_rate": 9.621083935804749e-05,
      "loss": 2.345,
      "step": 740
    },
    {
      "epoch": 0.11536686663590216,
      "grad_norm": 1.3892899751663208,
      "learning_rate": 9.61595651950982e-05,
      "loss": 2.3247,
      "step": 750
    },
    {
      "epoch": 0.11690509152438086,
      "grad_norm": 0.9079137444496155,
      "learning_rate": 9.61082910321489e-05,
      "loss": 2.5095,
      "step": 760
    },
    {
      "epoch": 0.11844331641285956,
      "grad_norm": 0.9309729933738708,
      "learning_rate": 9.60570168691996e-05,
      "loss": 2.3357,
      "step": 770
    },
    {
      "epoch": 0.11998154130133826,
      "grad_norm": 1.0791698694229126,
      "learning_rate": 9.600574270625033e-05,
      "loss": 2.3941,
      "step": 780
    },
    {
      "epoch": 0.12151976618981696,
      "grad_norm": 0.9481079578399658,
      "learning_rate": 9.595446854330104e-05,
      "loss": 2.3263,
      "step": 790
    },
    {
      "epoch": 0.12305799107829565,
      "grad_norm": 1.384405255317688,
      "learning_rate": 9.590319438035175e-05,
      "loss": 2.3435,
      "step": 800
    },
    {
      "epoch": 0.12459621596677434,
      "grad_norm": 0.9731020927429199,
      "learning_rate": 9.585192021740246e-05,
      "loss": 2.3627,
      "step": 810
    },
    {
      "epoch": 0.12613444085525305,
      "grad_norm": 0.7296550869941711,
      "learning_rate": 9.580064605445316e-05,
      "loss": 2.2322,
      "step": 820
    },
    {
      "epoch": 0.12767266574373173,
      "grad_norm": 1.0827419757843018,
      "learning_rate": 9.574937189150389e-05,
      "loss": 2.4777,
      "step": 830
    },
    {
      "epoch": 0.12921089063221042,
      "grad_norm": 0.99042809009552,
      "learning_rate": 9.569809772855458e-05,
      "loss": 2.4005,
      "step": 840
    },
    {
      "epoch": 0.13074911552068913,
      "grad_norm": 1.324620246887207,
      "learning_rate": 9.564682356560529e-05,
      "loss": 2.4839,
      "step": 850
    },
    {
      "epoch": 0.13228734040916781,
      "grad_norm": 1.4613444805145264,
      "learning_rate": 9.5595549402656e-05,
      "loss": 2.4002,
      "step": 860
    },
    {
      "epoch": 0.13382556529764653,
      "grad_norm": 0.9288026094436646,
      "learning_rate": 9.554427523970671e-05,
      "loss": 2.3541,
      "step": 870
    },
    {
      "epoch": 0.1353637901861252,
      "grad_norm": 1.129841685295105,
      "learning_rate": 9.549300107675743e-05,
      "loss": 2.3574,
      "step": 880
    },
    {
      "epoch": 0.1369020150746039,
      "grad_norm": 0.8787457346916199,
      "learning_rate": 9.544172691380814e-05,
      "loss": 2.3814,
      "step": 890
    },
    {
      "epoch": 0.1384402399630826,
      "grad_norm": 0.9640584588050842,
      "learning_rate": 9.539045275085885e-05,
      "loss": 2.3224,
      "step": 900
    },
    {
      "epoch": 0.1399784648515613,
      "grad_norm": 1.1772041320800781,
      "learning_rate": 9.533917858790956e-05,
      "loss": 2.3084,
      "step": 910
    },
    {
      "epoch": 0.14151668974004,
      "grad_norm": 0.8222691416740417,
      "learning_rate": 9.528790442496027e-05,
      "loss": 2.4192,
      "step": 920
    },
    {
      "epoch": 0.1430549146285187,
      "grad_norm": 0.8213545680046082,
      "learning_rate": 9.523663026201098e-05,
      "loss": 2.3573,
      "step": 930
    },
    {
      "epoch": 0.1445931395169974,
      "grad_norm": 1.1404590606689453,
      "learning_rate": 9.518535609906169e-05,
      "loss": 2.3049,
      "step": 940
    },
    {
      "epoch": 0.14613136440547608,
      "grad_norm": 1.1463240385055542,
      "learning_rate": 9.51340819361124e-05,
      "loss": 2.4483,
      "step": 950
    },
    {
      "epoch": 0.14766958929395477,
      "grad_norm": 1.2217503786087036,
      "learning_rate": 9.50828077731631e-05,
      "loss": 2.4451,
      "step": 960
    },
    {
      "epoch": 0.14920781418243348,
      "grad_norm": 0.8242997527122498,
      "learning_rate": 9.503153361021381e-05,
      "loss": 2.3317,
      "step": 970
    },
    {
      "epoch": 0.15074603907091216,
      "grad_norm": 1.1569207906723022,
      "learning_rate": 9.498025944726452e-05,
      "loss": 2.2817,
      "step": 980
    },
    {
      "epoch": 0.15228426395939088,
      "grad_norm": 1.1216130256652832,
      "learning_rate": 9.492898528431525e-05,
      "loss": 2.3543,
      "step": 990
    },
    {
      "epoch": 0.15382248884786956,
      "grad_norm": 1.131046175956726,
      "learning_rate": 9.487771112136596e-05,
      "loss": 2.3527,
      "step": 1000
    },
    {
      "epoch": 0.15536071373634824,
      "grad_norm": 1.2182101011276245,
      "learning_rate": 9.482643695841665e-05,
      "loss": 2.2678,
      "step": 1010
    },
    {
      "epoch": 0.15689893862482696,
      "grad_norm": 0.9577516317367554,
      "learning_rate": 9.477516279546736e-05,
      "loss": 2.4039,
      "step": 1020
    },
    {
      "epoch": 0.15843716351330564,
      "grad_norm": 1.0458829402923584,
      "learning_rate": 9.472388863251808e-05,
      "loss": 2.413,
      "step": 1030
    },
    {
      "epoch": 0.15997538840178435,
      "grad_norm": 0.9187437891960144,
      "learning_rate": 9.467261446956879e-05,
      "loss": 2.3664,
      "step": 1040
    },
    {
      "epoch": 0.16151361329026304,
      "grad_norm": 0.829723060131073,
      "learning_rate": 9.46213403066195e-05,
      "loss": 2.3837,
      "step": 1050
    },
    {
      "epoch": 0.16305183817874172,
      "grad_norm": 1.2389100790023804,
      "learning_rate": 9.457006614367021e-05,
      "loss": 2.3635,
      "step": 1060
    },
    {
      "epoch": 0.16459006306722043,
      "grad_norm": 1.0236015319824219,
      "learning_rate": 9.451879198072092e-05,
      "loss": 2.2544,
      "step": 1070
    },
    {
      "epoch": 0.16612828795569912,
      "grad_norm": 0.8570135831832886,
      "learning_rate": 9.446751781777163e-05,
      "loss": 2.3395,
      "step": 1080
    },
    {
      "epoch": 0.16766651284417783,
      "grad_norm": 0.9625948071479797,
      "learning_rate": 9.441624365482235e-05,
      "loss": 2.3859,
      "step": 1090
    },
    {
      "epoch": 0.1692047377326565,
      "grad_norm": 0.89539635181427,
      "learning_rate": 9.436496949187305e-05,
      "loss": 2.3562,
      "step": 1100
    },
    {
      "epoch": 0.1707429626211352,
      "grad_norm": 0.9785100221633911,
      "learning_rate": 9.431369532892376e-05,
      "loss": 2.2446,
      "step": 1110
    },
    {
      "epoch": 0.1722811875096139,
      "grad_norm": 1.1737624406814575,
      "learning_rate": 9.426242116597446e-05,
      "loss": 2.3936,
      "step": 1120
    },
    {
      "epoch": 0.1738194123980926,
      "grad_norm": 0.9451086521148682,
      "learning_rate": 9.421114700302517e-05,
      "loss": 2.4288,
      "step": 1130
    },
    {
      "epoch": 0.1753576372865713,
      "grad_norm": 0.8831786513328552,
      "learning_rate": 9.41598728400759e-05,
      "loss": 2.3756,
      "step": 1140
    },
    {
      "epoch": 0.17689586217505,
      "grad_norm": 1.3798778057098389,
      "learning_rate": 9.41085986771266e-05,
      "loss": 2.482,
      "step": 1150
    },
    {
      "epoch": 0.1784340870635287,
      "grad_norm": 0.9072500467300415,
      "learning_rate": 9.405732451417731e-05,
      "loss": 2.2366,
      "step": 1160
    },
    {
      "epoch": 0.17997231195200739,
      "grad_norm": 0.851820707321167,
      "learning_rate": 9.400605035122802e-05,
      "loss": 2.2708,
      "step": 1170
    },
    {
      "epoch": 0.18151053684048607,
      "grad_norm": 0.9339284300804138,
      "learning_rate": 9.395477618827873e-05,
      "loss": 2.268,
      "step": 1180
    },
    {
      "epoch": 0.18304876172896478,
      "grad_norm": 0.8741077184677124,
      "learning_rate": 9.390350202532944e-05,
      "loss": 2.3972,
      "step": 1190
    },
    {
      "epoch": 0.18458698661744347,
      "grad_norm": 1.1137354373931885,
      "learning_rate": 9.385222786238015e-05,
      "loss": 2.2709,
      "step": 1200
    },
    {
      "epoch": 0.18612521150592218,
      "grad_norm": 0.8969918489456177,
      "learning_rate": 9.380095369943086e-05,
      "loss": 2.3409,
      "step": 1210
    },
    {
      "epoch": 0.18766343639440086,
      "grad_norm": 1.399888515472412,
      "learning_rate": 9.374967953648157e-05,
      "loss": 2.356,
      "step": 1220
    },
    {
      "epoch": 0.18920166128287955,
      "grad_norm": 1.1646440029144287,
      "learning_rate": 9.369840537353228e-05,
      "loss": 2.3076,
      "step": 1230
    },
    {
      "epoch": 0.19073988617135826,
      "grad_norm": 1.1363041400909424,
      "learning_rate": 9.3647131210583e-05,
      "loss": 2.3777,
      "step": 1240
    },
    {
      "epoch": 0.19227811105983694,
      "grad_norm": 1.016471266746521,
      "learning_rate": 9.359585704763371e-05,
      "loss": 2.3759,
      "step": 1250
    },
    {
      "epoch": 0.19381633594831565,
      "grad_norm": 0.8463709950447083,
      "learning_rate": 9.354458288468442e-05,
      "loss": 2.2938,
      "step": 1260
    },
    {
      "epoch": 0.19535456083679434,
      "grad_norm": 1.0321208238601685,
      "learning_rate": 9.349330872173511e-05,
      "loss": 2.3482,
      "step": 1270
    },
    {
      "epoch": 0.19689278572527302,
      "grad_norm": 0.801830530166626,
      "learning_rate": 9.344203455878582e-05,
      "loss": 2.2615,
      "step": 1280
    },
    {
      "epoch": 0.19843101061375173,
      "grad_norm": 0.9908499121665955,
      "learning_rate": 9.339076039583655e-05,
      "loss": 2.2918,
      "step": 1290
    },
    {
      "epoch": 0.19996923550223042,
      "grad_norm": 0.9015299081802368,
      "learning_rate": 9.333948623288725e-05,
      "loss": 2.3913,
      "step": 1300
    },
    {
      "epoch": 0.20150746039070913,
      "grad_norm": 0.8517335653305054,
      "learning_rate": 9.328821206993796e-05,
      "loss": 2.3604,
      "step": 1310
    },
    {
      "epoch": 0.20304568527918782,
      "grad_norm": 0.7576839923858643,
      "learning_rate": 9.323693790698867e-05,
      "loss": 2.2648,
      "step": 1320
    },
    {
      "epoch": 0.2045839101676665,
      "grad_norm": 1.0572640895843506,
      "learning_rate": 9.318566374403938e-05,
      "loss": 2.3066,
      "step": 1330
    },
    {
      "epoch": 0.2061221350561452,
      "grad_norm": 1.2618391513824463,
      "learning_rate": 9.313438958109009e-05,
      "loss": 2.4479,
      "step": 1340
    },
    {
      "epoch": 0.2076603599446239,
      "grad_norm": 0.9082226753234863,
      "learning_rate": 9.30831154181408e-05,
      "loss": 2.319,
      "step": 1350
    },
    {
      "epoch": 0.2091985848331026,
      "grad_norm": 1.137063980102539,
      "learning_rate": 9.303184125519151e-05,
      "loss": 2.3538,
      "step": 1360
    },
    {
      "epoch": 0.2107368097215813,
      "grad_norm": 1.2156848907470703,
      "learning_rate": 9.298056709224222e-05,
      "loss": 2.3672,
      "step": 1370
    },
    {
      "epoch": 0.21227503461006,
      "grad_norm": 1.0615837574005127,
      "learning_rate": 9.292929292929293e-05,
      "loss": 2.318,
      "step": 1380
    },
    {
      "epoch": 0.2138132594985387,
      "grad_norm": 0.7031446695327759,
      "learning_rate": 9.287801876634365e-05,
      "loss": 2.3754,
      "step": 1390
    },
    {
      "epoch": 0.21535148438701737,
      "grad_norm": 1.0792100429534912,
      "learning_rate": 9.282674460339436e-05,
      "loss": 2.3928,
      "step": 1400
    },
    {
      "epoch": 0.21688970927549608,
      "grad_norm": 0.9547038078308105,
      "learning_rate": 9.277547044044507e-05,
      "loss": 2.3834,
      "step": 1410
    },
    {
      "epoch": 0.21842793416397477,
      "grad_norm": 0.9081752896308899,
      "learning_rate": 9.272419627749578e-05,
      "loss": 2.366,
      "step": 1420
    },
    {
      "epoch": 0.21996615905245348,
      "grad_norm": 0.8674251437187195,
      "learning_rate": 9.267292211454649e-05,
      "loss": 2.3302,
      "step": 1430
    },
    {
      "epoch": 0.22150438394093216,
      "grad_norm": 0.7524937391281128,
      "learning_rate": 9.26216479515972e-05,
      "loss": 2.3265,
      "step": 1440
    },
    {
      "epoch": 0.22304260882941085,
      "grad_norm": 1.0890637636184692,
      "learning_rate": 9.25703737886479e-05,
      "loss": 2.4002,
      "step": 1450
    },
    {
      "epoch": 0.22458083371788956,
      "grad_norm": 0.9604703783988953,
      "learning_rate": 9.251909962569861e-05,
      "loss": 2.3997,
      "step": 1460
    },
    {
      "epoch": 0.22611905860636825,
      "grad_norm": 0.9587043523788452,
      "learning_rate": 9.246782546274932e-05,
      "loss": 2.1888,
      "step": 1470
    },
    {
      "epoch": 0.22765728349484696,
      "grad_norm": 0.8627868294715881,
      "learning_rate": 9.241655129980003e-05,
      "loss": 2.2271,
      "step": 1480
    },
    {
      "epoch": 0.22919550838332564,
      "grad_norm": 1.6658141613006592,
      "learning_rate": 9.236527713685074e-05,
      "loss": 2.3808,
      "step": 1490
    },
    {
      "epoch": 0.23073373327180433,
      "grad_norm": 0.8292087316513062,
      "learning_rate": 9.231400297390146e-05,
      "loss": 2.3831,
      "step": 1500
    },
    {
      "epoch": 0.23227195816028304,
      "grad_norm": 1.0639952421188354,
      "learning_rate": 9.226272881095217e-05,
      "loss": 2.4253,
      "step": 1510
    },
    {
      "epoch": 0.23381018304876172,
      "grad_norm": 0.911286473274231,
      "learning_rate": 9.221145464800287e-05,
      "loss": 2.3882,
      "step": 1520
    },
    {
      "epoch": 0.23534840793724043,
      "grad_norm": 1.0653918981552124,
      "learning_rate": 9.216018048505358e-05,
      "loss": 2.262,
      "step": 1530
    },
    {
      "epoch": 0.23688663282571912,
      "grad_norm": 0.775364339351654,
      "learning_rate": 9.21089063221043e-05,
      "loss": 2.3303,
      "step": 1540
    },
    {
      "epoch": 0.2384248577141978,
      "grad_norm": 0.9708721041679382,
      "learning_rate": 9.205763215915501e-05,
      "loss": 2.2572,
      "step": 1550
    },
    {
      "epoch": 0.23996308260267651,
      "grad_norm": 1.3037928342819214,
      "learning_rate": 9.200635799620572e-05,
      "loss": 2.3202,
      "step": 1560
    },
    {
      "epoch": 0.2415013074911552,
      "grad_norm": 0.8447539210319519,
      "learning_rate": 9.195508383325643e-05,
      "loss": 2.3549,
      "step": 1570
    },
    {
      "epoch": 0.2430395323796339,
      "grad_norm": 0.9687184691429138,
      "learning_rate": 9.190380967030714e-05,
      "loss": 2.3997,
      "step": 1580
    },
    {
      "epoch": 0.2445777572681126,
      "grad_norm": 1.085591197013855,
      "learning_rate": 9.185253550735785e-05,
      "loss": 2.3954,
      "step": 1590
    },
    {
      "epoch": 0.2461159821565913,
      "grad_norm": 0.7975506782531738,
      "learning_rate": 9.180126134440857e-05,
      "loss": 2.4023,
      "step": 1600
    },
    {
      "epoch": 0.24765420704507,
      "grad_norm": 0.8976469039916992,
      "learning_rate": 9.174998718145926e-05,
      "loss": 2.2802,
      "step": 1610
    },
    {
      "epoch": 0.24919243193354867,
      "grad_norm": 1.018182396888733,
      "learning_rate": 9.169871301850997e-05,
      "loss": 2.3703,
      "step": 1620
    },
    {
      "epoch": 0.2507306568220274,
      "grad_norm": 0.7566492557525635,
      "learning_rate": 9.164743885556068e-05,
      "loss": 2.2385,
      "step": 1630
    },
    {
      "epoch": 0.2522688817105061,
      "grad_norm": 1.6852009296417236,
      "learning_rate": 9.159616469261139e-05,
      "loss": 2.367,
      "step": 1640
    },
    {
      "epoch": 0.25380710659898476,
      "grad_norm": 1.081018090248108,
      "learning_rate": 9.154489052966211e-05,
      "loss": 2.2997,
      "step": 1650
    },
    {
      "epoch": 0.25534533148746347,
      "grad_norm": 1.0540295839309692,
      "learning_rate": 9.149361636671282e-05,
      "loss": 2.2617,
      "step": 1660
    },
    {
      "epoch": 0.2568835563759422,
      "grad_norm": 1.0538369417190552,
      "learning_rate": 9.144234220376353e-05,
      "loss": 2.3,
      "step": 1670
    },
    {
      "epoch": 0.25842178126442084,
      "grad_norm": 0.8911623358726501,
      "learning_rate": 9.139106804081424e-05,
      "loss": 2.3207,
      "step": 1680
    },
    {
      "epoch": 0.25996000615289955,
      "grad_norm": 1.278957724571228,
      "learning_rate": 9.133979387786494e-05,
      "loss": 2.3398,
      "step": 1690
    },
    {
      "epoch": 0.26149823104137826,
      "grad_norm": 1.0844378471374512,
      "learning_rate": 9.128851971491566e-05,
      "loss": 2.3718,
      "step": 1700
    },
    {
      "epoch": 0.26303645592985697,
      "grad_norm": 0.988380491733551,
      "learning_rate": 9.123724555196637e-05,
      "loss": 2.3238,
      "step": 1710
    },
    {
      "epoch": 0.26457468081833563,
      "grad_norm": 0.7687071561813354,
      "learning_rate": 9.118597138901708e-05,
      "loss": 2.3395,
      "step": 1720
    },
    {
      "epoch": 0.26611290570681434,
      "grad_norm": 1.2303543090820312,
      "learning_rate": 9.113469722606779e-05,
      "loss": 2.3137,
      "step": 1730
    },
    {
      "epoch": 0.26765113059529305,
      "grad_norm": 1.3194670677185059,
      "learning_rate": 9.10834230631185e-05,
      "loss": 2.2938,
      "step": 1740
    },
    {
      "epoch": 0.2691893554837717,
      "grad_norm": 0.8565366268157959,
      "learning_rate": 9.103214890016922e-05,
      "loss": 2.1883,
      "step": 1750
    },
    {
      "epoch": 0.2707275803722504,
      "grad_norm": 0.9481441974639893,
      "learning_rate": 9.098087473721993e-05,
      "loss": 2.2142,
      "step": 1760
    },
    {
      "epoch": 0.27226580526072913,
      "grad_norm": 1.1457215547561646,
      "learning_rate": 9.092960057427064e-05,
      "loss": 2.3523,
      "step": 1770
    },
    {
      "epoch": 0.2738040301492078,
      "grad_norm": 0.8666920065879822,
      "learning_rate": 9.087832641132133e-05,
      "loss": 2.333,
      "step": 1780
    },
    {
      "epoch": 0.2753422550376865,
      "grad_norm": 0.9516326189041138,
      "learning_rate": 9.082705224837204e-05,
      "loss": 2.3227,
      "step": 1790
    },
    {
      "epoch": 0.2768804799261652,
      "grad_norm": 1.125641942024231,
      "learning_rate": 9.077577808542276e-05,
      "loss": 2.2811,
      "step": 1800
    },
    {
      "epoch": 0.2784187048146439,
      "grad_norm": 0.7248914837837219,
      "learning_rate": 9.072450392247347e-05,
      "loss": 2.229,
      "step": 1810
    },
    {
      "epoch": 0.2799569297031226,
      "grad_norm": 1.1648125648498535,
      "learning_rate": 9.067322975952418e-05,
      "loss": 2.3461,
      "step": 1820
    },
    {
      "epoch": 0.2814951545916013,
      "grad_norm": 0.9306198954582214,
      "learning_rate": 9.062195559657489e-05,
      "loss": 2.4411,
      "step": 1830
    },
    {
      "epoch": 0.28303337948008,
      "grad_norm": 0.8632981777191162,
      "learning_rate": 9.05706814336256e-05,
      "loss": 2.3147,
      "step": 1840
    },
    {
      "epoch": 0.28457160436855866,
      "grad_norm": 1.0031105279922485,
      "learning_rate": 9.051940727067631e-05,
      "loss": 2.2313,
      "step": 1850
    },
    {
      "epoch": 0.2861098292570374,
      "grad_norm": 1.087646484375,
      "learning_rate": 9.046813310772702e-05,
      "loss": 2.3478,
      "step": 1860
    },
    {
      "epoch": 0.2876480541455161,
      "grad_norm": 1.4194533824920654,
      "learning_rate": 9.041685894477773e-05,
      "loss": 2.2992,
      "step": 1870
    },
    {
      "epoch": 0.2891862790339948,
      "grad_norm": 0.7619257569313049,
      "learning_rate": 9.036558478182844e-05,
      "loss": 2.2513,
      "step": 1880
    },
    {
      "epoch": 0.29072450392247345,
      "grad_norm": 0.8279052376747131,
      "learning_rate": 9.031431061887915e-05,
      "loss": 2.2539,
      "step": 1890
    },
    {
      "epoch": 0.29226272881095217,
      "grad_norm": 1.0974736213684082,
      "learning_rate": 9.026303645592987e-05,
      "loss": 2.2179,
      "step": 1900
    },
    {
      "epoch": 0.2938009536994309,
      "grad_norm": 0.9489269256591797,
      "learning_rate": 9.021176229298058e-05,
      "loss": 2.3707,
      "step": 1910
    },
    {
      "epoch": 0.29533917858790953,
      "grad_norm": 1.0058236122131348,
      "learning_rate": 9.016048813003129e-05,
      "loss": 2.2795,
      "step": 1920
    },
    {
      "epoch": 0.29687740347638825,
      "grad_norm": 0.9993000626564026,
      "learning_rate": 9.0109213967082e-05,
      "loss": 2.3638,
      "step": 1930
    },
    {
      "epoch": 0.29841562836486696,
      "grad_norm": 1.0579222440719604,
      "learning_rate": 9.00579398041327e-05,
      "loss": 2.2531,
      "step": 1940
    },
    {
      "epoch": 0.2999538532533456,
      "grad_norm": 0.7501667141914368,
      "learning_rate": 9.000666564118341e-05,
      "loss": 2.2578,
      "step": 1950
    },
    {
      "epoch": 0.3014920781418243,
      "grad_norm": 1.1398831605911255,
      "learning_rate": 8.995539147823412e-05,
      "loss": 2.2054,
      "step": 1960
    },
    {
      "epoch": 0.30303030303030304,
      "grad_norm": 0.9692484140396118,
      "learning_rate": 8.990411731528483e-05,
      "loss": 2.2561,
      "step": 1970
    },
    {
      "epoch": 0.30456852791878175,
      "grad_norm": 1.1439406871795654,
      "learning_rate": 8.985284315233554e-05,
      "loss": 2.317,
      "step": 1980
    },
    {
      "epoch": 0.3061067528072604,
      "grad_norm": 0.9182436466217041,
      "learning_rate": 8.980156898938625e-05,
      "loss": 2.3221,
      "step": 1990
    },
    {
      "epoch": 0.3076449776957391,
      "grad_norm": 0.8540138602256775,
      "learning_rate": 8.975029482643696e-05,
      "loss": 2.258,
      "step": 2000
    },
    {
      "epoch": 0.30918320258421783,
      "grad_norm": 0.9826604127883911,
      "learning_rate": 8.969902066348768e-05,
      "loss": 2.3034,
      "step": 2010
    },
    {
      "epoch": 0.3107214274726965,
      "grad_norm": 0.9897715449333191,
      "learning_rate": 8.964774650053839e-05,
      "loss": 2.2375,
      "step": 2020
    },
    {
      "epoch": 0.3122596523611752,
      "grad_norm": 0.9915783405303955,
      "learning_rate": 8.959647233758909e-05,
      "loss": 2.282,
      "step": 2030
    },
    {
      "epoch": 0.3137978772496539,
      "grad_norm": 0.7774962782859802,
      "learning_rate": 8.95451981746398e-05,
      "loss": 2.2192,
      "step": 2040
    },
    {
      "epoch": 0.31533610213813257,
      "grad_norm": 1.0849714279174805,
      "learning_rate": 8.94939240116905e-05,
      "loss": 2.1735,
      "step": 2050
    },
    {
      "epoch": 0.3168743270266113,
      "grad_norm": 1.3296504020690918,
      "learning_rate": 8.944264984874123e-05,
      "loss": 2.3533,
      "step": 2060
    },
    {
      "epoch": 0.31841255191509,
      "grad_norm": 0.8607456684112549,
      "learning_rate": 8.939137568579194e-05,
      "loss": 2.2663,
      "step": 2070
    },
    {
      "epoch": 0.3199507768035687,
      "grad_norm": 0.9673560857772827,
      "learning_rate": 8.934010152284265e-05,
      "loss": 2.2401,
      "step": 2080
    },
    {
      "epoch": 0.32148900169204736,
      "grad_norm": 0.9406920075416565,
      "learning_rate": 8.928882735989335e-05,
      "loss": 2.3318,
      "step": 2090
    },
    {
      "epoch": 0.3230272265805261,
      "grad_norm": 0.9379817247390747,
      "learning_rate": 8.923755319694406e-05,
      "loss": 2.2699,
      "step": 2100
    },
    {
      "epoch": 0.3245654514690048,
      "grad_norm": 0.9792314767837524,
      "learning_rate": 8.918627903399479e-05,
      "loss": 2.312,
      "step": 2110
    },
    {
      "epoch": 0.32610367635748344,
      "grad_norm": 1.2682822942733765,
      "learning_rate": 8.913500487104548e-05,
      "loss": 2.1895,
      "step": 2120
    },
    {
      "epoch": 0.32764190124596215,
      "grad_norm": 1.0079998970031738,
      "learning_rate": 8.908373070809619e-05,
      "loss": 2.2983,
      "step": 2130
    },
    {
      "epoch": 0.32918012613444086,
      "grad_norm": 0.9478371739387512,
      "learning_rate": 8.90324565451469e-05,
      "loss": 2.3464,
      "step": 2140
    },
    {
      "epoch": 0.3307183510229196,
      "grad_norm": 1.0139496326446533,
      "learning_rate": 8.898118238219761e-05,
      "loss": 2.3395,
      "step": 2150
    },
    {
      "epoch": 0.33225657591139823,
      "grad_norm": 0.8629897832870483,
      "learning_rate": 8.892990821924833e-05,
      "loss": 2.2077,
      "step": 2160
    },
    {
      "epoch": 0.33379480079987695,
      "grad_norm": 1.4620726108551025,
      "learning_rate": 8.887863405629904e-05,
      "loss": 2.3096,
      "step": 2170
    },
    {
      "epoch": 0.33533302568835566,
      "grad_norm": 0.9702004790306091,
      "learning_rate": 8.882735989334975e-05,
      "loss": 2.3519,
      "step": 2180
    },
    {
      "epoch": 0.3368712505768343,
      "grad_norm": 0.9932650327682495,
      "learning_rate": 8.877608573040046e-05,
      "loss": 2.3453,
      "step": 2190
    },
    {
      "epoch": 0.338409475465313,
      "grad_norm": 0.9327139258384705,
      "learning_rate": 8.872481156745115e-05,
      "loss": 2.2213,
      "step": 2200
    },
    {
      "epoch": 0.33994770035379174,
      "grad_norm": 0.8932101130485535,
      "learning_rate": 8.867353740450188e-05,
      "loss": 2.3821,
      "step": 2210
    },
    {
      "epoch": 0.3414859252422704,
      "grad_norm": 0.8775930404663086,
      "learning_rate": 8.862226324155259e-05,
      "loss": 2.3518,
      "step": 2220
    },
    {
      "epoch": 0.3430241501307491,
      "grad_norm": 1.0364453792572021,
      "learning_rate": 8.85709890786033e-05,
      "loss": 2.2383,
      "step": 2230
    },
    {
      "epoch": 0.3445623750192278,
      "grad_norm": 0.8616227507591248,
      "learning_rate": 8.8519714915654e-05,
      "loss": 2.2831,
      "step": 2240
    },
    {
      "epoch": 0.34610059990770653,
      "grad_norm": 1.1039588451385498,
      "learning_rate": 8.846844075270471e-05,
      "loss": 2.1571,
      "step": 2250
    },
    {
      "epoch": 0.3476388247961852,
      "grad_norm": 0.9709256887435913,
      "learning_rate": 8.841716658975544e-05,
      "loss": 2.4468,
      "step": 2260
    },
    {
      "epoch": 0.3491770496846639,
      "grad_norm": 1.002502679824829,
      "learning_rate": 8.836589242680614e-05,
      "loss": 2.3132,
      "step": 2270
    },
    {
      "epoch": 0.3507152745731426,
      "grad_norm": 0.9301533699035645,
      "learning_rate": 8.831461826385685e-05,
      "loss": 2.2703,
      "step": 2280
    },
    {
      "epoch": 0.35225349946162127,
      "grad_norm": 0.7622637748718262,
      "learning_rate": 8.826334410090755e-05,
      "loss": 2.3035,
      "step": 2290
    },
    {
      "epoch": 0.3537917243501,
      "grad_norm": 1.1477632522583008,
      "learning_rate": 8.821206993795826e-05,
      "loss": 2.3787,
      "step": 2300
    },
    {
      "epoch": 0.3553299492385787,
      "grad_norm": 0.7521834969520569,
      "learning_rate": 8.816079577500898e-05,
      "loss": 2.3054,
      "step": 2310
    },
    {
      "epoch": 0.3568681741270574,
      "grad_norm": 0.8684582114219666,
      "learning_rate": 8.810952161205969e-05,
      "loss": 2.2498,
      "step": 2320
    },
    {
      "epoch": 0.35840639901553606,
      "grad_norm": 0.8882172107696533,
      "learning_rate": 8.80582474491104e-05,
      "loss": 2.2009,
      "step": 2330
    },
    {
      "epoch": 0.35994462390401477,
      "grad_norm": 0.9389574527740479,
      "learning_rate": 8.800697328616111e-05,
      "loss": 2.2551,
      "step": 2340
    },
    {
      "epoch": 0.3614828487924935,
      "grad_norm": 0.7628786563873291,
      "learning_rate": 8.795569912321182e-05,
      "loss": 2.2782,
      "step": 2350
    },
    {
      "epoch": 0.36302107368097214,
      "grad_norm": 1.4449824094772339,
      "learning_rate": 8.790442496026253e-05,
      "loss": 2.3346,
      "step": 2360
    },
    {
      "epoch": 0.36455929856945085,
      "grad_norm": 0.8784567713737488,
      "learning_rate": 8.785315079731324e-05,
      "loss": 2.3712,
      "step": 2370
    },
    {
      "epoch": 0.36609752345792956,
      "grad_norm": 0.9509233236312866,
      "learning_rate": 8.780187663436394e-05,
      "loss": 2.2112,
      "step": 2380
    },
    {
      "epoch": 0.3676357483464082,
      "grad_norm": 0.7432436347007751,
      "learning_rate": 8.775060247141465e-05,
      "loss": 2.2662,
      "step": 2390
    },
    {
      "epoch": 0.36917397323488693,
      "grad_norm": 0.7712249755859375,
      "learning_rate": 8.769932830846536e-05,
      "loss": 2.1885,
      "step": 2400
    },
    {
      "epoch": 0.37071219812336564,
      "grad_norm": 0.9576478600502014,
      "learning_rate": 8.764805414551607e-05,
      "loss": 2.267,
      "step": 2410
    },
    {
      "epoch": 0.37225042301184436,
      "grad_norm": 0.8779605627059937,
      "learning_rate": 8.75967799825668e-05,
      "loss": 2.246,
      "step": 2420
    },
    {
      "epoch": 0.373788647900323,
      "grad_norm": 0.8408971428871155,
      "learning_rate": 8.75455058196175e-05,
      "loss": 2.2216,
      "step": 2430
    },
    {
      "epoch": 0.3753268727888017,
      "grad_norm": 0.9785459637641907,
      "learning_rate": 8.749423165666821e-05,
      "loss": 2.3978,
      "step": 2440
    },
    {
      "epoch": 0.37686509767728044,
      "grad_norm": 1.1419650316238403,
      "learning_rate": 8.744295749371892e-05,
      "loss": 2.3577,
      "step": 2450
    },
    {
      "epoch": 0.3784033225657591,
      "grad_norm": 0.8390716314315796,
      "learning_rate": 8.739168333076963e-05,
      "loss": 2.2553,
      "step": 2460
    },
    {
      "epoch": 0.3799415474542378,
      "grad_norm": 0.7990594506263733,
      "learning_rate": 8.734040916782034e-05,
      "loss": 2.3093,
      "step": 2470
    },
    {
      "epoch": 0.3814797723427165,
      "grad_norm": 0.9870525002479553,
      "learning_rate": 8.728913500487105e-05,
      "loss": 2.2984,
      "step": 2480
    },
    {
      "epoch": 0.3830179972311952,
      "grad_norm": 1.096959114074707,
      "learning_rate": 8.723786084192176e-05,
      "loss": 2.2643,
      "step": 2490
    },
    {
      "epoch": 0.3845562221196739,
      "grad_norm": 0.9146120548248291,
      "learning_rate": 8.718658667897247e-05,
      "loss": 2.3411,
      "step": 2500
    },
    {
      "epoch": 0.3860944470081526,
      "grad_norm": 0.8757959008216858,
      "learning_rate": 8.713531251602318e-05,
      "loss": 2.2722,
      "step": 2510
    },
    {
      "epoch": 0.3876326718966313,
      "grad_norm": 1.1926383972167969,
      "learning_rate": 8.70840383530739e-05,
      "loss": 2.327,
      "step": 2520
    },
    {
      "epoch": 0.38917089678510997,
      "grad_norm": 0.9634771943092346,
      "learning_rate": 8.703276419012461e-05,
      "loss": 2.2203,
      "step": 2530
    },
    {
      "epoch": 0.3907091216735887,
      "grad_norm": 1.119310975074768,
      "learning_rate": 8.69814900271753e-05,
      "loss": 2.3041,
      "step": 2540
    },
    {
      "epoch": 0.3922473465620674,
      "grad_norm": 0.788459062576294,
      "learning_rate": 8.693021586422601e-05,
      "loss": 2.2488,
      "step": 2550
    },
    {
      "epoch": 0.39378557145054605,
      "grad_norm": 0.9462425708770752,
      "learning_rate": 8.687894170127672e-05,
      "loss": 2.255,
      "step": 2560
    },
    {
      "epoch": 0.39532379633902476,
      "grad_norm": 0.9861125349998474,
      "learning_rate": 8.682766753832744e-05,
      "loss": 2.2465,
      "step": 2570
    },
    {
      "epoch": 0.39686202122750347,
      "grad_norm": 1.1777220964431763,
      "learning_rate": 8.677639337537815e-05,
      "loss": 2.2967,
      "step": 2580
    },
    {
      "epoch": 0.3984002461159822,
      "grad_norm": 1.0811834335327148,
      "learning_rate": 8.672511921242886e-05,
      "loss": 2.2712,
      "step": 2590
    },
    {
      "epoch": 0.39993847100446084,
      "grad_norm": 1.0035991668701172,
      "learning_rate": 8.667384504947957e-05,
      "loss": 2.3246,
      "step": 2600
    },
    {
      "epoch": 0.40147669589293955,
      "grad_norm": 0.956218421459198,
      "learning_rate": 8.662257088653028e-05,
      "loss": 2.1974,
      "step": 2610
    },
    {
      "epoch": 0.40301492078141826,
      "grad_norm": 1.0518748760223389,
      "learning_rate": 8.6571296723581e-05,
      "loss": 2.3071,
      "step": 2620
    },
    {
      "epoch": 0.4045531456698969,
      "grad_norm": 1.1680355072021484,
      "learning_rate": 8.65200225606317e-05,
      "loss": 2.4153,
      "step": 2630
    },
    {
      "epoch": 0.40609137055837563,
      "grad_norm": 0.9885054230690002,
      "learning_rate": 8.646874839768241e-05,
      "loss": 2.3113,
      "step": 2640
    },
    {
      "epoch": 0.40762959544685434,
      "grad_norm": 0.8083099126815796,
      "learning_rate": 8.641747423473312e-05,
      "loss": 2.3058,
      "step": 2650
    },
    {
      "epoch": 0.409167820335333,
      "grad_norm": 1.118858814239502,
      "learning_rate": 8.636620007178383e-05,
      "loss": 2.3899,
      "step": 2660
    },
    {
      "epoch": 0.4107060452238117,
      "grad_norm": 0.8994693160057068,
      "learning_rate": 8.631492590883455e-05,
      "loss": 2.3393,
      "step": 2670
    },
    {
      "epoch": 0.4122442701122904,
      "grad_norm": 0.7934942245483398,
      "learning_rate": 8.626365174588526e-05,
      "loss": 2.3531,
      "step": 2680
    },
    {
      "epoch": 0.41378249500076913,
      "grad_norm": 1.1432355642318726,
      "learning_rate": 8.621237758293597e-05,
      "loss": 2.3171,
      "step": 2690
    },
    {
      "epoch": 0.4153207198892478,
      "grad_norm": 1.0568222999572754,
      "learning_rate": 8.616110341998668e-05,
      "loss": 2.2949,
      "step": 2700
    },
    {
      "epoch": 0.4168589447777265,
      "grad_norm": 1.3339487314224243,
      "learning_rate": 8.610982925703737e-05,
      "loss": 2.2467,
      "step": 2710
    },
    {
      "epoch": 0.4183971696662052,
      "grad_norm": 0.891101062297821,
      "learning_rate": 8.60585550940881e-05,
      "loss": 2.1772,
      "step": 2720
    },
    {
      "epoch": 0.41993539455468387,
      "grad_norm": 0.9895696640014648,
      "learning_rate": 8.60072809311388e-05,
      "loss": 2.2511,
      "step": 2730
    },
    {
      "epoch": 0.4214736194431626,
      "grad_norm": 1.5037952661514282,
      "learning_rate": 8.595600676818951e-05,
      "loss": 2.3094,
      "step": 2740
    },
    {
      "epoch": 0.4230118443316413,
      "grad_norm": 1.3172814846038818,
      "learning_rate": 8.590473260524022e-05,
      "loss": 2.2435,
      "step": 2750
    },
    {
      "epoch": 0.42455006922012,
      "grad_norm": 1.0354995727539062,
      "learning_rate": 8.585345844229093e-05,
      "loss": 2.2546,
      "step": 2760
    },
    {
      "epoch": 0.42608829410859866,
      "grad_norm": 0.7781267762184143,
      "learning_rate": 8.580218427934164e-05,
      "loss": 2.2895,
      "step": 2770
    },
    {
      "epoch": 0.4276265189970774,
      "grad_norm": 0.9660653471946716,
      "learning_rate": 8.575091011639236e-05,
      "loss": 2.3258,
      "step": 2780
    },
    {
      "epoch": 0.4291647438855561,
      "grad_norm": 1.0293235778808594,
      "learning_rate": 8.569963595344307e-05,
      "loss": 2.1913,
      "step": 2790
    },
    {
      "epoch": 0.43070296877403474,
      "grad_norm": 0.9636089205741882,
      "learning_rate": 8.564836179049377e-05,
      "loss": 2.2229,
      "step": 2800
    },
    {
      "epoch": 0.43224119366251346,
      "grad_norm": 1.0417877435684204,
      "learning_rate": 8.559708762754448e-05,
      "loss": 2.2899,
      "step": 2810
    },
    {
      "epoch": 0.43377941855099217,
      "grad_norm": 0.9344021081924438,
      "learning_rate": 8.55458134645952e-05,
      "loss": 2.184,
      "step": 2820
    },
    {
      "epoch": 0.4353176434394708,
      "grad_norm": 0.6903371810913086,
      "learning_rate": 8.549453930164591e-05,
      "loss": 2.3606,
      "step": 2830
    },
    {
      "epoch": 0.43685586832794954,
      "grad_norm": 0.9873772859573364,
      "learning_rate": 8.544326513869662e-05,
      "loss": 2.2671,
      "step": 2840
    },
    {
      "epoch": 0.43839409321642825,
      "grad_norm": 0.8802867531776428,
      "learning_rate": 8.539199097574733e-05,
      "loss": 2.3309,
      "step": 2850
    },
    {
      "epoch": 0.43993231810490696,
      "grad_norm": 1.0014759302139282,
      "learning_rate": 8.534071681279804e-05,
      "loss": 2.3369,
      "step": 2860
    },
    {
      "epoch": 0.4414705429933856,
      "grad_norm": 0.9903216361999512,
      "learning_rate": 8.528944264984874e-05,
      "loss": 2.2767,
      "step": 2870
    },
    {
      "epoch": 0.44300876788186433,
      "grad_norm": 0.8472523093223572,
      "learning_rate": 8.523816848689945e-05,
      "loss": 2.3227,
      "step": 2880
    },
    {
      "epoch": 0.44454699277034304,
      "grad_norm": 0.9691609740257263,
      "learning_rate": 8.518689432395016e-05,
      "loss": 2.4172,
      "step": 2890
    },
    {
      "epoch": 0.4460852176588217,
      "grad_norm": 1.1441282033920288,
      "learning_rate": 8.513562016100087e-05,
      "loss": 2.2578,
      "step": 2900
    },
    {
      "epoch": 0.4476234425473004,
      "grad_norm": 0.9551346302032471,
      "learning_rate": 8.508434599805158e-05,
      "loss": 2.2904,
      "step": 2910
    },
    {
      "epoch": 0.4491616674357791,
      "grad_norm": 0.8791012167930603,
      "learning_rate": 8.503307183510229e-05,
      "loss": 2.3203,
      "step": 2920
    },
    {
      "epoch": 0.45069989232425783,
      "grad_norm": 0.9215505719184875,
      "learning_rate": 8.498179767215301e-05,
      "loss": 2.2702,
      "step": 2930
    },
    {
      "epoch": 0.4522381172127365,
      "grad_norm": 0.9251764416694641,
      "learning_rate": 8.493052350920372e-05,
      "loss": 2.1976,
      "step": 2940
    },
    {
      "epoch": 0.4537763421012152,
      "grad_norm": 0.9312923550605774,
      "learning_rate": 8.487924934625443e-05,
      "loss": 2.2651,
      "step": 2950
    },
    {
      "epoch": 0.4553145669896939,
      "grad_norm": 1.0302073955535889,
      "learning_rate": 8.482797518330514e-05,
      "loss": 2.2914,
      "step": 2960
    },
    {
      "epoch": 0.45685279187817257,
      "grad_norm": 1.1868935823440552,
      "learning_rate": 8.477670102035585e-05,
      "loss": 2.3211,
      "step": 2970
    },
    {
      "epoch": 0.4583910167666513,
      "grad_norm": 0.8748847246170044,
      "learning_rate": 8.472542685740656e-05,
      "loss": 2.3304,
      "step": 2980
    },
    {
      "epoch": 0.45992924165513,
      "grad_norm": 0.9357801079750061,
      "learning_rate": 8.467415269445727e-05,
      "loss": 2.298,
      "step": 2990
    },
    {
      "epoch": 0.46146746654360865,
      "grad_norm": 0.940485954284668,
      "learning_rate": 8.462287853150798e-05,
      "loss": 2.3305,
      "step": 3000
    },
    {
      "epoch": 0.46300569143208736,
      "grad_norm": 0.9531272649765015,
      "learning_rate": 8.457160436855869e-05,
      "loss": 2.3077,
      "step": 3010
    },
    {
      "epoch": 0.4645439163205661,
      "grad_norm": 0.9768287539482117,
      "learning_rate": 8.45203302056094e-05,
      "loss": 2.2359,
      "step": 3020
    },
    {
      "epoch": 0.4660821412090448,
      "grad_norm": 0.9510540962219238,
      "learning_rate": 8.446905604266012e-05,
      "loss": 2.3435,
      "step": 3030
    },
    {
      "epoch": 0.46762036609752344,
      "grad_norm": 1.1645132303237915,
      "learning_rate": 8.441778187971083e-05,
      "loss": 2.2255,
      "step": 3040
    },
    {
      "epoch": 0.46915859098600216,
      "grad_norm": 0.6672899723052979,
      "learning_rate": 8.436650771676152e-05,
      "loss": 2.2322,
      "step": 3050
    },
    {
      "epoch": 0.47069681587448087,
      "grad_norm": 0.9119551181793213,
      "learning_rate": 8.431523355381223e-05,
      "loss": 2.2992,
      "step": 3060
    },
    {
      "epoch": 0.4722350407629595,
      "grad_norm": 0.9865890145301819,
      "learning_rate": 8.426395939086294e-05,
      "loss": 2.3073,
      "step": 3070
    },
    {
      "epoch": 0.47377326565143824,
      "grad_norm": 1.192719578742981,
      "learning_rate": 8.421268522791366e-05,
      "loss": 2.309,
      "step": 3080
    },
    {
      "epoch": 0.47531149053991695,
      "grad_norm": 0.8836092948913574,
      "learning_rate": 8.416141106496437e-05,
      "loss": 2.2698,
      "step": 3090
    },
    {
      "epoch": 0.4768497154283956,
      "grad_norm": 0.8378663063049316,
      "learning_rate": 8.411013690201508e-05,
      "loss": 2.3078,
      "step": 3100
    },
    {
      "epoch": 0.4783879403168743,
      "grad_norm": 1.0443509817123413,
      "learning_rate": 8.405886273906579e-05,
      "loss": 2.2434,
      "step": 3110
    },
    {
      "epoch": 0.47992616520535303,
      "grad_norm": 1.077728509902954,
      "learning_rate": 8.40075885761165e-05,
      "loss": 2.2901,
      "step": 3120
    },
    {
      "epoch": 0.48146439009383174,
      "grad_norm": 1.0350403785705566,
      "learning_rate": 8.395631441316721e-05,
      "loss": 2.2862,
      "step": 3130
    },
    {
      "epoch": 0.4830026149823104,
      "grad_norm": 1.062722086906433,
      "learning_rate": 8.390504025021792e-05,
      "loss": 2.203,
      "step": 3140
    },
    {
      "epoch": 0.4845408398707891,
      "grad_norm": 0.7822374701499939,
      "learning_rate": 8.385376608726863e-05,
      "loss": 2.2845,
      "step": 3150
    },
    {
      "epoch": 0.4860790647592678,
      "grad_norm": 1.0216268301010132,
      "learning_rate": 8.380249192431933e-05,
      "loss": 2.2627,
      "step": 3160
    },
    {
      "epoch": 0.4876172896477465,
      "grad_norm": 0.7049469351768494,
      "learning_rate": 8.375121776137004e-05,
      "loss": 2.226,
      "step": 3170
    },
    {
      "epoch": 0.4891555145362252,
      "grad_norm": 0.8990631103515625,
      "learning_rate": 8.369994359842077e-05,
      "loss": 2.2634,
      "step": 3180
    },
    {
      "epoch": 0.4906937394247039,
      "grad_norm": 1.1030187606811523,
      "learning_rate": 8.364866943547148e-05,
      "loss": 2.3319,
      "step": 3190
    },
    {
      "epoch": 0.4922319643131826,
      "grad_norm": 0.8706591129302979,
      "learning_rate": 8.359739527252218e-05,
      "loss": 2.2735,
      "step": 3200
    },
    {
      "epoch": 0.49377018920166127,
      "grad_norm": 1.1134240627288818,
      "learning_rate": 8.35461211095729e-05,
      "loss": 2.2,
      "step": 3210
    },
    {
      "epoch": 0.49530841409014,
      "grad_norm": 0.8919715881347656,
      "learning_rate": 8.349484694662359e-05,
      "loss": 2.3366,
      "step": 3220
    },
    {
      "epoch": 0.4968466389786187,
      "grad_norm": 0.8236812353134155,
      "learning_rate": 8.344357278367431e-05,
      "loss": 2.2746,
      "step": 3230
    },
    {
      "epoch": 0.49838486386709735,
      "grad_norm": 0.7762203216552734,
      "learning_rate": 8.339229862072502e-05,
      "loss": 2.2766,
      "step": 3240
    },
    {
      "epoch": 0.49992308875557606,
      "grad_norm": 0.7744325399398804,
      "learning_rate": 8.334102445777573e-05,
      "loss": 2.3017,
      "step": 3250
    },
    {
      "epoch": 0.5014613136440548,
      "grad_norm": 1.2258903980255127,
      "learning_rate": 8.328975029482644e-05,
      "loss": 2.21,
      "step": 3260
    },
    {
      "epoch": 0.5029995385325334,
      "grad_norm": 0.735567033290863,
      "learning_rate": 8.323847613187715e-05,
      "loss": 2.3122,
      "step": 3270
    },
    {
      "epoch": 0.5045377634210122,
      "grad_norm": 1.1336249113082886,
      "learning_rate": 8.318720196892786e-05,
      "loss": 2.2535,
      "step": 3280
    },
    {
      "epoch": 0.5060759883094909,
      "grad_norm": 0.8732126355171204,
      "learning_rate": 8.313592780597858e-05,
      "loss": 2.3059,
      "step": 3290
    },
    {
      "epoch": 0.5076142131979695,
      "grad_norm": 1.1084136962890625,
      "learning_rate": 8.308465364302929e-05,
      "loss": 2.2459,
      "step": 3300
    },
    {
      "epoch": 0.5091524380864483,
      "grad_norm": 0.9033851623535156,
      "learning_rate": 8.303337948007998e-05,
      "loss": 2.2607,
      "step": 3310
    },
    {
      "epoch": 0.5106906629749269,
      "grad_norm": 0.8595645427703857,
      "learning_rate": 8.29821053171307e-05,
      "loss": 2.2776,
      "step": 3320
    },
    {
      "epoch": 0.5122288878634056,
      "grad_norm": 0.8238754868507385,
      "learning_rate": 8.293083115418142e-05,
      "loss": 2.2605,
      "step": 3330
    },
    {
      "epoch": 0.5137671127518844,
      "grad_norm": 1.060767412185669,
      "learning_rate": 8.287955699123213e-05,
      "loss": 2.2651,
      "step": 3340
    },
    {
      "epoch": 0.515305337640363,
      "grad_norm": 1.2983146905899048,
      "learning_rate": 8.282828282828283e-05,
      "loss": 2.223,
      "step": 3350
    },
    {
      "epoch": 0.5168435625288417,
      "grad_norm": 1.1229500770568848,
      "learning_rate": 8.277700866533354e-05,
      "loss": 2.2844,
      "step": 3360
    },
    {
      "epoch": 0.5183817874173204,
      "grad_norm": 1.26649808883667,
      "learning_rate": 8.272573450238425e-05,
      "loss": 2.2858,
      "step": 3370
    },
    {
      "epoch": 0.5199200123057991,
      "grad_norm": 1.1915905475616455,
      "learning_rate": 8.267446033943496e-05,
      "loss": 2.3307,
      "step": 3380
    },
    {
      "epoch": 0.5214582371942778,
      "grad_norm": 0.9278625249862671,
      "learning_rate": 8.262318617648567e-05,
      "loss": 2.1453,
      "step": 3390
    },
    {
      "epoch": 0.5229964620827565,
      "grad_norm": 1.1981624364852905,
      "learning_rate": 8.257191201353638e-05,
      "loss": 2.3982,
      "step": 3400
    },
    {
      "epoch": 0.5245346869712352,
      "grad_norm": 1.0816112756729126,
      "learning_rate": 8.252063785058709e-05,
      "loss": 2.2832,
      "step": 3410
    },
    {
      "epoch": 0.5260729118597139,
      "grad_norm": 0.8670153021812439,
      "learning_rate": 8.24693636876378e-05,
      "loss": 2.3417,
      "step": 3420
    },
    {
      "epoch": 0.5276111367481926,
      "grad_norm": 1.2614654302597046,
      "learning_rate": 8.241808952468851e-05,
      "loss": 2.4044,
      "step": 3430
    },
    {
      "epoch": 0.5291493616366713,
      "grad_norm": 0.7703715562820435,
      "learning_rate": 8.236681536173923e-05,
      "loss": 2.2177,
      "step": 3440
    },
    {
      "epoch": 0.53068758652515,
      "grad_norm": 0.9281696081161499,
      "learning_rate": 8.231554119878994e-05,
      "loss": 2.2878,
      "step": 3450
    },
    {
      "epoch": 0.5322258114136287,
      "grad_norm": 0.9404263496398926,
      "learning_rate": 8.226426703584065e-05,
      "loss": 2.2975,
      "step": 3460
    },
    {
      "epoch": 0.5337640363021073,
      "grad_norm": 0.9033923149108887,
      "learning_rate": 8.221299287289136e-05,
      "loss": 2.2868,
      "step": 3470
    },
    {
      "epoch": 0.5353022611905861,
      "grad_norm": 1.2245683670043945,
      "learning_rate": 8.216171870994205e-05,
      "loss": 2.2436,
      "step": 3480
    },
    {
      "epoch": 0.5368404860790648,
      "grad_norm": 1.0220428705215454,
      "learning_rate": 8.211044454699278e-05,
      "loss": 2.2025,
      "step": 3490
    },
    {
      "epoch": 0.5383787109675434,
      "grad_norm": 1.0416522026062012,
      "learning_rate": 8.205917038404348e-05,
      "loss": 2.2463,
      "step": 3500
    },
    {
      "epoch": 0.5399169358560222,
      "grad_norm": 0.6994608044624329,
      "learning_rate": 8.20078962210942e-05,
      "loss": 2.2395,
      "step": 3510
    },
    {
      "epoch": 0.5414551607445008,
      "grad_norm": 0.8843719363212585,
      "learning_rate": 8.19566220581449e-05,
      "loss": 2.2328,
      "step": 3520
    },
    {
      "epoch": 0.5429933856329795,
      "grad_norm": 1.028660535812378,
      "learning_rate": 8.190534789519561e-05,
      "loss": 2.3549,
      "step": 3530
    },
    {
      "epoch": 0.5445316105214583,
      "grad_norm": 0.9257699847221375,
      "learning_rate": 8.185407373224633e-05,
      "loss": 2.2681,
      "step": 3540
    },
    {
      "epoch": 0.5460698354099369,
      "grad_norm": 0.8043977618217468,
      "learning_rate": 8.180279956929704e-05,
      "loss": 2.3699,
      "step": 3550
    },
    {
      "epoch": 0.5476080602984156,
      "grad_norm": 0.9151738286018372,
      "learning_rate": 8.175152540634774e-05,
      "loss": 2.2009,
      "step": 3560
    },
    {
      "epoch": 0.5491462851868943,
      "grad_norm": 1.049837350845337,
      "learning_rate": 8.170025124339845e-05,
      "loss": 2.288,
      "step": 3570
    },
    {
      "epoch": 0.550684510075373,
      "grad_norm": 1.450932264328003,
      "learning_rate": 8.164897708044916e-05,
      "loss": 2.272,
      "step": 3580
    },
    {
      "epoch": 0.5522227349638518,
      "grad_norm": 1.2276291847229004,
      "learning_rate": 8.159770291749988e-05,
      "loss": 2.2971,
      "step": 3590
    },
    {
      "epoch": 0.5537609598523304,
      "grad_norm": 0.9161737561225891,
      "learning_rate": 8.154642875455059e-05,
      "loss": 2.2038,
      "step": 3600
    },
    {
      "epoch": 0.5552991847408091,
      "grad_norm": 1.1927571296691895,
      "learning_rate": 8.14951545916013e-05,
      "loss": 2.2854,
      "step": 3610
    },
    {
      "epoch": 0.5568374096292878,
      "grad_norm": 0.6979355216026306,
      "learning_rate": 8.144388042865201e-05,
      "loss": 2.2999,
      "step": 3620
    },
    {
      "epoch": 0.5583756345177665,
      "grad_norm": 0.9130053520202637,
      "learning_rate": 8.139260626570272e-05,
      "loss": 2.3795,
      "step": 3630
    },
    {
      "epoch": 0.5599138594062452,
      "grad_norm": 1.0155171155929565,
      "learning_rate": 8.134133210275343e-05,
      "loss": 2.2,
      "step": 3640
    },
    {
      "epoch": 0.5614520842947239,
      "grad_norm": 0.9678864479064941,
      "learning_rate": 8.129005793980413e-05,
      "loss": 2.2825,
      "step": 3650
    },
    {
      "epoch": 0.5629903091832026,
      "grad_norm": 0.8350366353988647,
      "learning_rate": 8.123878377685484e-05,
      "loss": 2.2517,
      "step": 3660
    },
    {
      "epoch": 0.5645285340716812,
      "grad_norm": 0.8489223718643188,
      "learning_rate": 8.118750961390555e-05,
      "loss": 2.1966,
      "step": 3670
    },
    {
      "epoch": 0.56606675896016,
      "grad_norm": 1.1302565336227417,
      "learning_rate": 8.113623545095626e-05,
      "loss": 2.2821,
      "step": 3680
    },
    {
      "epoch": 0.5676049838486387,
      "grad_norm": 0.9800832271575928,
      "learning_rate": 8.108496128800697e-05,
      "loss": 2.2397,
      "step": 3690
    },
    {
      "epoch": 0.5691432087371173,
      "grad_norm": 0.9763533473014832,
      "learning_rate": 8.10336871250577e-05,
      "loss": 2.2371,
      "step": 3700
    },
    {
      "epoch": 0.5706814336255961,
      "grad_norm": 0.9713611006736755,
      "learning_rate": 8.09824129621084e-05,
      "loss": 2.2798,
      "step": 3710
    },
    {
      "epoch": 0.5722196585140747,
      "grad_norm": 1.1376091241836548,
      "learning_rate": 8.093113879915911e-05,
      "loss": 2.2782,
      "step": 3720
    },
    {
      "epoch": 0.5737578834025534,
      "grad_norm": 1.0999871492385864,
      "learning_rate": 8.087986463620981e-05,
      "loss": 2.1898,
      "step": 3730
    },
    {
      "epoch": 0.5752961082910322,
      "grad_norm": 1.0685678720474243,
      "learning_rate": 8.082859047326053e-05,
      "loss": 2.2232,
      "step": 3740
    },
    {
      "epoch": 0.5768343331795108,
      "grad_norm": 1.1431108713150024,
      "learning_rate": 8.077731631031124e-05,
      "loss": 2.3659,
      "step": 3750
    },
    {
      "epoch": 0.5783725580679896,
      "grad_norm": 1.0472077131271362,
      "learning_rate": 8.072604214736195e-05,
      "loss": 2.3059,
      "step": 3760
    },
    {
      "epoch": 0.5799107829564683,
      "grad_norm": 0.8702605962753296,
      "learning_rate": 8.067476798441266e-05,
      "loss": 2.3398,
      "step": 3770
    },
    {
      "epoch": 0.5814490078449469,
      "grad_norm": 1.093851923942566,
      "learning_rate": 8.062349382146337e-05,
      "loss": 2.1867,
      "step": 3780
    },
    {
      "epoch": 0.5829872327334257,
      "grad_norm": 0.724114179611206,
      "learning_rate": 8.057221965851408e-05,
      "loss": 2.3143,
      "step": 3790
    },
    {
      "epoch": 0.5845254576219043,
      "grad_norm": 0.9057135581970215,
      "learning_rate": 8.05209454955648e-05,
      "loss": 2.3214,
      "step": 3800
    },
    {
      "epoch": 0.586063682510383,
      "grad_norm": 0.6639223098754883,
      "learning_rate": 8.046967133261551e-05,
      "loss": 2.2851,
      "step": 3810
    },
    {
      "epoch": 0.5876019073988618,
      "grad_norm": 1.3725916147232056,
      "learning_rate": 8.04183971696662e-05,
      "loss": 2.2662,
      "step": 3820
    },
    {
      "epoch": 0.5891401322873404,
      "grad_norm": 0.8195849061012268,
      "learning_rate": 8.036712300671691e-05,
      "loss": 2.2739,
      "step": 3830
    },
    {
      "epoch": 0.5906783571758191,
      "grad_norm": 0.8284996747970581,
      "learning_rate": 8.031584884376762e-05,
      "loss": 2.2324,
      "step": 3840
    },
    {
      "epoch": 0.5922165820642978,
      "grad_norm": 0.9314028024673462,
      "learning_rate": 8.026457468081834e-05,
      "loss": 2.2935,
      "step": 3850
    },
    {
      "epoch": 0.5937548069527765,
      "grad_norm": 1.0108957290649414,
      "learning_rate": 8.021330051786905e-05,
      "loss": 2.3278,
      "step": 3860
    },
    {
      "epoch": 0.5952930318412551,
      "grad_norm": 0.7974213361740112,
      "learning_rate": 8.016202635491976e-05,
      "loss": 2.3402,
      "step": 3870
    },
    {
      "epoch": 0.5968312567297339,
      "grad_norm": 0.9947394728660583,
      "learning_rate": 8.011075219197047e-05,
      "loss": 2.2891,
      "step": 3880
    },
    {
      "epoch": 0.5983694816182126,
      "grad_norm": 0.8337937593460083,
      "learning_rate": 8.005947802902118e-05,
      "loss": 2.3236,
      "step": 3890
    },
    {
      "epoch": 0.5999077065066912,
      "grad_norm": 1.0671648979187012,
      "learning_rate": 8.000820386607189e-05,
      "loss": 2.2449,
      "step": 3900
    },
    {
      "epoch": 0.60144593139517,
      "grad_norm": 1.0902202129364014,
      "learning_rate": 7.99569297031226e-05,
      "loss": 2.1888,
      "step": 3910
    },
    {
      "epoch": 0.6029841562836487,
      "grad_norm": 1.0076961517333984,
      "learning_rate": 7.990565554017331e-05,
      "loss": 2.264,
      "step": 3920
    },
    {
      "epoch": 0.6045223811721273,
      "grad_norm": 0.7949910759925842,
      "learning_rate": 7.985438137722402e-05,
      "loss": 2.1501,
      "step": 3930
    },
    {
      "epoch": 0.6060606060606061,
      "grad_norm": 1.109812617301941,
      "learning_rate": 7.980310721427473e-05,
      "loss": 2.2365,
      "step": 3940
    },
    {
      "epoch": 0.6075988309490847,
      "grad_norm": 0.794342577457428,
      "learning_rate": 7.975183305132545e-05,
      "loss": 2.2831,
      "step": 3950
    },
    {
      "epoch": 0.6091370558375635,
      "grad_norm": 1.271654725074768,
      "learning_rate": 7.970055888837616e-05,
      "loss": 2.2758,
      "step": 3960
    },
    {
      "epoch": 0.6106752807260422,
      "grad_norm": 1.0191633701324463,
      "learning_rate": 7.964928472542687e-05,
      "loss": 2.3247,
      "step": 3970
    },
    {
      "epoch": 0.6122135056145208,
      "grad_norm": 0.8968227505683899,
      "learning_rate": 7.959801056247758e-05,
      "loss": 2.2861,
      "step": 3980
    },
    {
      "epoch": 0.6137517305029996,
      "grad_norm": 0.9603545665740967,
      "learning_rate": 7.954673639952827e-05,
      "loss": 2.2216,
      "step": 3990
    },
    {
      "epoch": 0.6152899553914782,
      "grad_norm": 0.7971410751342773,
      "learning_rate": 7.949546223657899e-05,
      "loss": 2.3794,
      "step": 4000
    },
    {
      "epoch": 0.6168281802799569,
      "grad_norm": 1.0451804399490356,
      "learning_rate": 7.94441880736297e-05,
      "loss": 2.2356,
      "step": 4010
    },
    {
      "epoch": 0.6183664051684357,
      "grad_norm": 1.0473926067352295,
      "learning_rate": 7.939291391068041e-05,
      "loss": 2.3069,
      "step": 4020
    },
    {
      "epoch": 0.6199046300569143,
      "grad_norm": 0.947273850440979,
      "learning_rate": 7.934163974773112e-05,
      "loss": 2.2615,
      "step": 4030
    },
    {
      "epoch": 0.621442854945393,
      "grad_norm": 0.874394953250885,
      "learning_rate": 7.929036558478183e-05,
      "loss": 2.3116,
      "step": 4040
    },
    {
      "epoch": 0.6229810798338717,
      "grad_norm": 1.0951088666915894,
      "learning_rate": 7.923909142183254e-05,
      "loss": 2.1982,
      "step": 4050
    },
    {
      "epoch": 0.6245193047223504,
      "grad_norm": 0.9210543036460876,
      "learning_rate": 7.918781725888326e-05,
      "loss": 2.2729,
      "step": 4060
    },
    {
      "epoch": 0.626057529610829,
      "grad_norm": 0.9173935651779175,
      "learning_rate": 7.913654309593397e-05,
      "loss": 2.3797,
      "step": 4070
    },
    {
      "epoch": 0.6275957544993078,
      "grad_norm": 1.1533770561218262,
      "learning_rate": 7.908526893298467e-05,
      "loss": 2.285,
      "step": 4080
    },
    {
      "epoch": 0.6291339793877865,
      "grad_norm": 1.2429746389389038,
      "learning_rate": 7.903399477003537e-05,
      "loss": 2.1504,
      "step": 4090
    },
    {
      "epoch": 0.6306722042762651,
      "grad_norm": 1.1552990674972534,
      "learning_rate": 7.89827206070861e-05,
      "loss": 2.3997,
      "step": 4100
    },
    {
      "epoch": 0.6322104291647439,
      "grad_norm": 0.942487895488739,
      "learning_rate": 7.89314464441368e-05,
      "loss": 2.2289,
      "step": 4110
    },
    {
      "epoch": 0.6337486540532226,
      "grad_norm": 1.0609931945800781,
      "learning_rate": 7.888017228118752e-05,
      "loss": 2.2794,
      "step": 4120
    },
    {
      "epoch": 0.6352868789417013,
      "grad_norm": 0.8204750418663025,
      "learning_rate": 7.882889811823822e-05,
      "loss": 2.0831,
      "step": 4130
    },
    {
      "epoch": 0.63682510383018,
      "grad_norm": 1.0106064081192017,
      "learning_rate": 7.877762395528893e-05,
      "loss": 2.2514,
      "step": 4140
    },
    {
      "epoch": 0.6383633287186586,
      "grad_norm": 1.204485297203064,
      "learning_rate": 7.872634979233964e-05,
      "loss": 2.2396,
      "step": 4150
    },
    {
      "epoch": 0.6399015536071374,
      "grad_norm": 0.9396007061004639,
      "learning_rate": 7.867507562939035e-05,
      "loss": 2.1642,
      "step": 4160
    },
    {
      "epoch": 0.6414397784956161,
      "grad_norm": 0.7816550731658936,
      "learning_rate": 7.862380146644106e-05,
      "loss": 2.2748,
      "step": 4170
    },
    {
      "epoch": 0.6429780033840947,
      "grad_norm": 1.0923268795013428,
      "learning_rate": 7.857252730349177e-05,
      "loss": 2.2577,
      "step": 4180
    },
    {
      "epoch": 0.6445162282725735,
      "grad_norm": 1.3657886981964111,
      "learning_rate": 7.852125314054248e-05,
      "loss": 2.2674,
      "step": 4190
    },
    {
      "epoch": 0.6460544531610521,
      "grad_norm": 1.1553798913955688,
      "learning_rate": 7.846997897759319e-05,
      "loss": 2.2941,
      "step": 4200
    },
    {
      "epoch": 0.6475926780495308,
      "grad_norm": 0.9940907955169678,
      "learning_rate": 7.841870481464391e-05,
      "loss": 2.2614,
      "step": 4210
    },
    {
      "epoch": 0.6491309029380096,
      "grad_norm": 0.7628971934318542,
      "learning_rate": 7.836743065169462e-05,
      "loss": 2.2925,
      "step": 4220
    },
    {
      "epoch": 0.6506691278264882,
      "grad_norm": 1.0765738487243652,
      "learning_rate": 7.831615648874533e-05,
      "loss": 2.3804,
      "step": 4230
    },
    {
      "epoch": 0.6522073527149669,
      "grad_norm": 0.942196249961853,
      "learning_rate": 7.826488232579604e-05,
      "loss": 2.3432,
      "step": 4240
    },
    {
      "epoch": 0.6537455776034456,
      "grad_norm": 1.014135479927063,
      "learning_rate": 7.821360816284675e-05,
      "loss": 2.2915,
      "step": 4250
    },
    {
      "epoch": 0.6552838024919243,
      "grad_norm": 0.9838641881942749,
      "learning_rate": 7.816233399989746e-05,
      "loss": 2.2821,
      "step": 4260
    },
    {
      "epoch": 0.656822027380403,
      "grad_norm": 0.9333420395851135,
      "learning_rate": 7.811105983694817e-05,
      "loss": 2.3422,
      "step": 4270
    },
    {
      "epoch": 0.6583602522688817,
      "grad_norm": 0.735694408416748,
      "learning_rate": 7.805978567399887e-05,
      "loss": 2.2558,
      "step": 4280
    },
    {
      "epoch": 0.6598984771573604,
      "grad_norm": 0.7827758193016052,
      "learning_rate": 7.800851151104958e-05,
      "loss": 2.3126,
      "step": 4290
    },
    {
      "epoch": 0.6614367020458392,
      "grad_norm": 1.021981120109558,
      "learning_rate": 7.795723734810029e-05,
      "loss": 2.2273,
      "step": 4300
    },
    {
      "epoch": 0.6629749269343178,
      "grad_norm": 0.8203487396240234,
      "learning_rate": 7.790596318515102e-05,
      "loss": 2.2541,
      "step": 4310
    },
    {
      "epoch": 0.6645131518227965,
      "grad_norm": 0.8656752109527588,
      "learning_rate": 7.785468902220172e-05,
      "loss": 2.2875,
      "step": 4320
    },
    {
      "epoch": 0.6660513767112752,
      "grad_norm": 1.2824372053146362,
      "learning_rate": 7.780341485925242e-05,
      "loss": 2.3113,
      "step": 4330
    },
    {
      "epoch": 0.6675896015997539,
      "grad_norm": 0.9605523943901062,
      "learning_rate": 7.775214069630313e-05,
      "loss": 2.2122,
      "step": 4340
    },
    {
      "epoch": 0.6691278264882325,
      "grad_norm": 1.0512597560882568,
      "learning_rate": 7.770086653335384e-05,
      "loss": 2.2528,
      "step": 4350
    },
    {
      "epoch": 0.6706660513767113,
      "grad_norm": 1.185811996459961,
      "learning_rate": 7.764959237040456e-05,
      "loss": 2.3408,
      "step": 4360
    },
    {
      "epoch": 0.67220427626519,
      "grad_norm": 0.9985898733139038,
      "learning_rate": 7.759831820745527e-05,
      "loss": 2.2154,
      "step": 4370
    },
    {
      "epoch": 0.6737425011536686,
      "grad_norm": 0.751891016960144,
      "learning_rate": 7.754704404450598e-05,
      "loss": 2.3509,
      "step": 4380
    },
    {
      "epoch": 0.6752807260421474,
      "grad_norm": 1.003220558166504,
      "learning_rate": 7.749576988155669e-05,
      "loss": 2.2126,
      "step": 4390
    },
    {
      "epoch": 0.676818950930626,
      "grad_norm": 1.0016852617263794,
      "learning_rate": 7.74444957186074e-05,
      "loss": 2.2416,
      "step": 4400
    },
    {
      "epoch": 0.6783571758191047,
      "grad_norm": 1.2870945930480957,
      "learning_rate": 7.73932215556581e-05,
      "loss": 2.2499,
      "step": 4410
    },
    {
      "epoch": 0.6798954007075835,
      "grad_norm": 1.0454813241958618,
      "learning_rate": 7.734194739270882e-05,
      "loss": 2.1733,
      "step": 4420
    },
    {
      "epoch": 0.6814336255960621,
      "grad_norm": 0.9748649597167969,
      "learning_rate": 7.729067322975952e-05,
      "loss": 2.2782,
      "step": 4430
    },
    {
      "epoch": 0.6829718504845408,
      "grad_norm": 0.9756820201873779,
      "learning_rate": 7.723939906681023e-05,
      "loss": 2.2745,
      "step": 4440
    },
    {
      "epoch": 0.6845100753730196,
      "grad_norm": 0.9698076844215393,
      "learning_rate": 7.718812490386094e-05,
      "loss": 2.2202,
      "step": 4450
    },
    {
      "epoch": 0.6860483002614982,
      "grad_norm": 0.9341872930526733,
      "learning_rate": 7.713685074091167e-05,
      "loss": 2.3069,
      "step": 4460
    },
    {
      "epoch": 0.687586525149977,
      "grad_norm": 1.050493597984314,
      "learning_rate": 7.708557657796237e-05,
      "loss": 2.25,
      "step": 4470
    },
    {
      "epoch": 0.6891247500384556,
      "grad_norm": 0.9203276634216309,
      "learning_rate": 7.703430241501308e-05,
      "loss": 2.3215,
      "step": 4480
    },
    {
      "epoch": 0.6906629749269343,
      "grad_norm": 1.1797164678573608,
      "learning_rate": 7.698302825206379e-05,
      "loss": 2.2553,
      "step": 4490
    },
    {
      "epoch": 0.6922011998154131,
      "grad_norm": 0.9404436349868774,
      "learning_rate": 7.693175408911449e-05,
      "loss": 2.2661,
      "step": 4500
    },
    {
      "epoch": 0.6937394247038917,
      "grad_norm": 0.9498058557510376,
      "learning_rate": 7.688047992616521e-05,
      "loss": 2.2899,
      "step": 4510
    },
    {
      "epoch": 0.6952776495923704,
      "grad_norm": 0.9099103212356567,
      "learning_rate": 7.682920576321592e-05,
      "loss": 2.2275,
      "step": 4520
    },
    {
      "epoch": 0.6968158744808491,
      "grad_norm": 1.0453510284423828,
      "learning_rate": 7.677793160026663e-05,
      "loss": 2.2335,
      "step": 4530
    },
    {
      "epoch": 0.6983540993693278,
      "grad_norm": 0.9092657566070557,
      "learning_rate": 7.672665743731734e-05,
      "loss": 2.2522,
      "step": 4540
    },
    {
      "epoch": 0.6998923242578065,
      "grad_norm": 0.9033746123313904,
      "learning_rate": 7.667538327436805e-05,
      "loss": 2.2731,
      "step": 4550
    },
    {
      "epoch": 0.7014305491462852,
      "grad_norm": 0.9081783890724182,
      "learning_rate": 7.662410911141876e-05,
      "loss": 2.1745,
      "step": 4560
    },
    {
      "epoch": 0.7029687740347639,
      "grad_norm": 1.2342073917388916,
      "learning_rate": 7.657283494846948e-05,
      "loss": 2.2233,
      "step": 4570
    },
    {
      "epoch": 0.7045069989232425,
      "grad_norm": 0.7935805320739746,
      "learning_rate": 7.652156078552019e-05,
      "loss": 2.2367,
      "step": 4580
    },
    {
      "epoch": 0.7060452238117213,
      "grad_norm": 0.950691282749176,
      "learning_rate": 7.647028662257088e-05,
      "loss": 2.1708,
      "step": 4590
    },
    {
      "epoch": 0.7075834487002,
      "grad_norm": 0.9970605969429016,
      "learning_rate": 7.641901245962159e-05,
      "loss": 2.2263,
      "step": 4600
    },
    {
      "epoch": 0.7091216735886786,
      "grad_norm": 1.1420639753341675,
      "learning_rate": 7.636773829667232e-05,
      "loss": 2.2582,
      "step": 4610
    },
    {
      "epoch": 0.7106598984771574,
      "grad_norm": 0.7424219846725464,
      "learning_rate": 7.631646413372302e-05,
      "loss": 2.2598,
      "step": 4620
    },
    {
      "epoch": 0.712198123365636,
      "grad_norm": 1.5658825635910034,
      "learning_rate": 7.626518997077373e-05,
      "loss": 2.142,
      "step": 4630
    },
    {
      "epoch": 0.7137363482541148,
      "grad_norm": 0.9133700132369995,
      "learning_rate": 7.621391580782444e-05,
      "loss": 2.2623,
      "step": 4640
    },
    {
      "epoch": 0.7152745731425935,
      "grad_norm": 1.068502426147461,
      "learning_rate": 7.616264164487515e-05,
      "loss": 2.267,
      "step": 4650
    },
    {
      "epoch": 0.7168127980310721,
      "grad_norm": 1.0619014501571655,
      "learning_rate": 7.611136748192586e-05,
      "loss": 2.204,
      "step": 4660
    },
    {
      "epoch": 0.7183510229195509,
      "grad_norm": 1.0259928703308105,
      "learning_rate": 7.606009331897657e-05,
      "loss": 2.2087,
      "step": 4670
    },
    {
      "epoch": 0.7198892478080295,
      "grad_norm": 0.9558602571487427,
      "learning_rate": 7.600881915602728e-05,
      "loss": 2.3066,
      "step": 4680
    },
    {
      "epoch": 0.7214274726965082,
      "grad_norm": 0.8789914846420288,
      "learning_rate": 7.595754499307799e-05,
      "loss": 2.2427,
      "step": 4690
    },
    {
      "epoch": 0.722965697584987,
      "grad_norm": 0.7384855151176453,
      "learning_rate": 7.59062708301287e-05,
      "loss": 2.3097,
      "step": 4700
    },
    {
      "epoch": 0.7245039224734656,
      "grad_norm": 1.436777114868164,
      "learning_rate": 7.58549966671794e-05,
      "loss": 2.336,
      "step": 4710
    },
    {
      "epoch": 0.7260421473619443,
      "grad_norm": 1.107456088066101,
      "learning_rate": 7.580372250423013e-05,
      "loss": 2.2619,
      "step": 4720
    },
    {
      "epoch": 0.727580372250423,
      "grad_norm": 1.0099685192108154,
      "learning_rate": 7.575244834128084e-05,
      "loss": 2.1765,
      "step": 4730
    },
    {
      "epoch": 0.7291185971389017,
      "grad_norm": 0.9844733476638794,
      "learning_rate": 7.570117417833155e-05,
      "loss": 2.3043,
      "step": 4740
    },
    {
      "epoch": 0.7306568220273804,
      "grad_norm": 0.8987894058227539,
      "learning_rate": 7.564990001538226e-05,
      "loss": 2.211,
      "step": 4750
    },
    {
      "epoch": 0.7321950469158591,
      "grad_norm": 0.9688206911087036,
      "learning_rate": 7.559862585243295e-05,
      "loss": 2.2408,
      "step": 4760
    },
    {
      "epoch": 0.7337332718043378,
      "grad_norm": 0.7387644052505493,
      "learning_rate": 7.554735168948367e-05,
      "loss": 2.1095,
      "step": 4770
    },
    {
      "epoch": 0.7352714966928164,
      "grad_norm": 0.7593515515327454,
      "learning_rate": 7.549607752653438e-05,
      "loss": 2.2496,
      "step": 4780
    },
    {
      "epoch": 0.7368097215812952,
      "grad_norm": 0.9634992480278015,
      "learning_rate": 7.544480336358509e-05,
      "loss": 2.2122,
      "step": 4790
    },
    {
      "epoch": 0.7383479464697739,
      "grad_norm": 1.1826181411743164,
      "learning_rate": 7.53935292006358e-05,
      "loss": 2.2495,
      "step": 4800
    },
    {
      "epoch": 0.7398861713582526,
      "grad_norm": 1.2440179586410522,
      "learning_rate": 7.534225503768651e-05,
      "loss": 2.3306,
      "step": 4810
    },
    {
      "epoch": 0.7414243962467313,
      "grad_norm": 1.012631893157959,
      "learning_rate": 7.529098087473723e-05,
      "loss": 2.1683,
      "step": 4820
    },
    {
      "epoch": 0.7429626211352099,
      "grad_norm": 1.084709882736206,
      "learning_rate": 7.523970671178794e-05,
      "loss": 2.1787,
      "step": 4830
    },
    {
      "epoch": 0.7445008460236887,
      "grad_norm": 1.0068249702453613,
      "learning_rate": 7.518843254883864e-05,
      "loss": 2.2355,
      "step": 4840
    },
    {
      "epoch": 0.7460390709121674,
      "grad_norm": 0.9928891062736511,
      "learning_rate": 7.513715838588935e-05,
      "loss": 2.1968,
      "step": 4850
    },
    {
      "epoch": 0.747577295800646,
      "grad_norm": 0.7048836350440979,
      "learning_rate": 7.508588422294006e-05,
      "loss": 2.3027,
      "step": 4860
    },
    {
      "epoch": 0.7491155206891248,
      "grad_norm": 0.9245229363441467,
      "learning_rate": 7.503461005999078e-05,
      "loss": 2.4051,
      "step": 4870
    },
    {
      "epoch": 0.7506537455776034,
      "grad_norm": 1.040338158607483,
      "learning_rate": 7.498333589704149e-05,
      "loss": 2.1853,
      "step": 4880
    },
    {
      "epoch": 0.7521919704660821,
      "grad_norm": 1.2731951475143433,
      "learning_rate": 7.49320617340922e-05,
      "loss": 2.284,
      "step": 4890
    },
    {
      "epoch": 0.7537301953545609,
      "grad_norm": 0.9600399732589722,
      "learning_rate": 7.48807875711429e-05,
      "loss": 2.3067,
      "step": 4900
    },
    {
      "epoch": 0.7552684202430395,
      "grad_norm": 0.884634256362915,
      "learning_rate": 7.482951340819362e-05,
      "loss": 2.2977,
      "step": 4910
    },
    {
      "epoch": 0.7568066451315182,
      "grad_norm": 0.8731624484062195,
      "learning_rate": 7.477823924524432e-05,
      "loss": 2.1175,
      "step": 4920
    },
    {
      "epoch": 0.758344870019997,
      "grad_norm": 0.7847326993942261,
      "learning_rate": 7.472696508229503e-05,
      "loss": 2.2962,
      "step": 4930
    },
    {
      "epoch": 0.7598830949084756,
      "grad_norm": 0.8660029172897339,
      "learning_rate": 7.467569091934574e-05,
      "loss": 2.2773,
      "step": 4940
    },
    {
      "epoch": 0.7614213197969543,
      "grad_norm": 0.7519541382789612,
      "learning_rate": 7.462441675639645e-05,
      "loss": 2.1479,
      "step": 4950
    },
    {
      "epoch": 0.762959544685433,
      "grad_norm": 1.08848237991333,
      "learning_rate": 7.457314259344716e-05,
      "loss": 2.2684,
      "step": 4960
    },
    {
      "epoch": 0.7644977695739117,
      "grad_norm": 1.2584805488586426,
      "learning_rate": 7.452186843049788e-05,
      "loss": 2.2282,
      "step": 4970
    },
    {
      "epoch": 0.7660359944623903,
      "grad_norm": 0.6932703256607056,
      "learning_rate": 7.447059426754859e-05,
      "loss": 2.2857,
      "step": 4980
    },
    {
      "epoch": 0.7675742193508691,
      "grad_norm": 0.8964722156524658,
      "learning_rate": 7.44193201045993e-05,
      "loss": 2.2534,
      "step": 4990
    },
    {
      "epoch": 0.7691124442393478,
      "grad_norm": 0.8847284913063049,
      "learning_rate": 7.436804594165001e-05,
      "loss": 2.2668,
      "step": 5000
    },
    {
      "epoch": 0.7706506691278265,
      "grad_norm": 0.8581270575523376,
      "learning_rate": 7.43167717787007e-05,
      "loss": 2.3018,
      "step": 5010
    },
    {
      "epoch": 0.7721888940163052,
      "grad_norm": 0.8274509906768799,
      "learning_rate": 7.426549761575143e-05,
      "loss": 2.2103,
      "step": 5020
    },
    {
      "epoch": 0.7737271189047839,
      "grad_norm": 0.846322774887085,
      "learning_rate": 7.421422345280214e-05,
      "loss": 2.2702,
      "step": 5030
    },
    {
      "epoch": 0.7752653437932626,
      "grad_norm": 1.1150062084197998,
      "learning_rate": 7.416294928985285e-05,
      "loss": 2.2521,
      "step": 5040
    },
    {
      "epoch": 0.7768035686817413,
      "grad_norm": 0.7525955438613892,
      "learning_rate": 7.411167512690356e-05,
      "loss": 2.2489,
      "step": 5050
    },
    {
      "epoch": 0.7783417935702199,
      "grad_norm": 0.8830128908157349,
      "learning_rate": 7.406040096395426e-05,
      "loss": 2.1661,
      "step": 5060
    },
    {
      "epoch": 0.7798800184586987,
      "grad_norm": 0.8543822765350342,
      "learning_rate": 7.400912680100497e-05,
      "loss": 2.2444,
      "step": 5070
    },
    {
      "epoch": 0.7814182433471774,
      "grad_norm": 0.8688601851463318,
      "learning_rate": 7.39578526380557e-05,
      "loss": 2.2858,
      "step": 5080
    },
    {
      "epoch": 0.782956468235656,
      "grad_norm": 1.069812297821045,
      "learning_rate": 7.39065784751064e-05,
      "loss": 2.1302,
      "step": 5090
    },
    {
      "epoch": 0.7844946931241348,
      "grad_norm": 0.8430496454238892,
      "learning_rate": 7.38553043121571e-05,
      "loss": 2.2757,
      "step": 5100
    },
    {
      "epoch": 0.7860329180126134,
      "grad_norm": 1.1058140993118286,
      "learning_rate": 7.380403014920781e-05,
      "loss": 2.2925,
      "step": 5110
    },
    {
      "epoch": 0.7875711429010921,
      "grad_norm": 1.010941505432129,
      "learning_rate": 7.375275598625852e-05,
      "loss": 2.1927,
      "step": 5120
    },
    {
      "epoch": 0.7891093677895709,
      "grad_norm": 0.9515459537506104,
      "learning_rate": 7.370148182330924e-05,
      "loss": 2.2652,
      "step": 5130
    },
    {
      "epoch": 0.7906475926780495,
      "grad_norm": 0.8635461926460266,
      "learning_rate": 7.365020766035995e-05,
      "loss": 2.2836,
      "step": 5140
    },
    {
      "epoch": 0.7921858175665282,
      "grad_norm": 0.8600487112998962,
      "learning_rate": 7.359893349741066e-05,
      "loss": 2.1996,
      "step": 5150
    },
    {
      "epoch": 0.7937240424550069,
      "grad_norm": 0.7502825856208801,
      "learning_rate": 7.354765933446137e-05,
      "loss": 2.2872,
      "step": 5160
    },
    {
      "epoch": 0.7952622673434856,
      "grad_norm": 0.9785138368606567,
      "learning_rate": 7.349638517151208e-05,
      "loss": 2.3074,
      "step": 5170
    },
    {
      "epoch": 0.7968004922319644,
      "grad_norm": 1.2859026193618774,
      "learning_rate": 7.344511100856279e-05,
      "loss": 2.2713,
      "step": 5180
    },
    {
      "epoch": 0.798338717120443,
      "grad_norm": 1.0041223764419556,
      "learning_rate": 7.33938368456135e-05,
      "loss": 2.1834,
      "step": 5190
    },
    {
      "epoch": 0.7998769420089217,
      "grad_norm": 1.150036096572876,
      "learning_rate": 7.33425626826642e-05,
      "loss": 2.1648,
      "step": 5200
    },
    {
      "epoch": 0.8014151668974004,
      "grad_norm": 1.1334002017974854,
      "learning_rate": 7.329128851971491e-05,
      "loss": 2.1831,
      "step": 5210
    },
    {
      "epoch": 0.8029533917858791,
      "grad_norm": 1.0058833360671997,
      "learning_rate": 7.324001435676562e-05,
      "loss": 2.3494,
      "step": 5220
    },
    {
      "epoch": 0.8044916166743578,
      "grad_norm": 0.9355576038360596,
      "learning_rate": 7.318874019381635e-05,
      "loss": 2.1909,
      "step": 5230
    },
    {
      "epoch": 0.8060298415628365,
      "grad_norm": 1.2194485664367676,
      "learning_rate": 7.313746603086706e-05,
      "loss": 2.2947,
      "step": 5240
    },
    {
      "epoch": 0.8075680664513152,
      "grad_norm": 1.13444185256958,
      "learning_rate": 7.308619186791776e-05,
      "loss": 2.2308,
      "step": 5250
    },
    {
      "epoch": 0.8091062913397938,
      "grad_norm": 1.0807734727859497,
      "learning_rate": 7.303491770496847e-05,
      "loss": 2.2756,
      "step": 5260
    },
    {
      "epoch": 0.8106445162282726,
      "grad_norm": 0.8338256478309631,
      "learning_rate": 7.298364354201917e-05,
      "loss": 2.2144,
      "step": 5270
    },
    {
      "epoch": 0.8121827411167513,
      "grad_norm": 0.8104408383369446,
      "learning_rate": 7.293236937906989e-05,
      "loss": 2.3796,
      "step": 5280
    },
    {
      "epoch": 0.8137209660052299,
      "grad_norm": 1.2390092611312866,
      "learning_rate": 7.28810952161206e-05,
      "loss": 2.2159,
      "step": 5290
    },
    {
      "epoch": 0.8152591908937087,
      "grad_norm": 0.8285899758338928,
      "learning_rate": 7.282982105317131e-05,
      "loss": 2.1799,
      "step": 5300
    },
    {
      "epoch": 0.8167974157821873,
      "grad_norm": 0.9037333726882935,
      "learning_rate": 7.277854689022202e-05,
      "loss": 2.3264,
      "step": 5310
    },
    {
      "epoch": 0.818335640670666,
      "grad_norm": 0.9882908463478088,
      "learning_rate": 7.272727272727273e-05,
      "loss": 2.2153,
      "step": 5320
    },
    {
      "epoch": 0.8198738655591448,
      "grad_norm": 0.9364275932312012,
      "learning_rate": 7.267599856432345e-05,
      "loss": 2.2294,
      "step": 5330
    },
    {
      "epoch": 0.8214120904476234,
      "grad_norm": 0.7310437560081482,
      "learning_rate": 7.262472440137416e-05,
      "loss": 2.326,
      "step": 5340
    },
    {
      "epoch": 0.8229503153361022,
      "grad_norm": 0.8150128126144409,
      "learning_rate": 7.257345023842486e-05,
      "loss": 2.1678,
      "step": 5350
    },
    {
      "epoch": 0.8244885402245808,
      "grad_norm": 1.2194074392318726,
      "learning_rate": 7.252217607547556e-05,
      "loss": 2.2033,
      "step": 5360
    },
    {
      "epoch": 0.8260267651130595,
      "grad_norm": 0.8046772480010986,
      "learning_rate": 7.247090191252627e-05,
      "loss": 2.2217,
      "step": 5370
    },
    {
      "epoch": 0.8275649900015383,
      "grad_norm": 0.903985321521759,
      "learning_rate": 7.2419627749577e-05,
      "loss": 2.2619,
      "step": 5380
    },
    {
      "epoch": 0.8291032148900169,
      "grad_norm": 0.7844682931900024,
      "learning_rate": 7.23683535866277e-05,
      "loss": 2.2619,
      "step": 5390
    },
    {
      "epoch": 0.8306414397784956,
      "grad_norm": 0.7035439610481262,
      "learning_rate": 7.231707942367841e-05,
      "loss": 2.263,
      "step": 5400
    },
    {
      "epoch": 0.8321796646669744,
      "grad_norm": 1.0288983583450317,
      "learning_rate": 7.226580526072912e-05,
      "loss": 2.3107,
      "step": 5410
    },
    {
      "epoch": 0.833717889555453,
      "grad_norm": 0.8949504494667053,
      "learning_rate": 7.221453109777983e-05,
      "loss": 2.2298,
      "step": 5420
    },
    {
      "epoch": 0.8352561144439317,
      "grad_norm": 1.0483810901641846,
      "learning_rate": 7.216325693483054e-05,
      "loss": 2.2856,
      "step": 5430
    },
    {
      "epoch": 0.8367943393324104,
      "grad_norm": 0.9200074672698975,
      "learning_rate": 7.211198277188125e-05,
      "loss": 2.3732,
      "step": 5440
    },
    {
      "epoch": 0.8383325642208891,
      "grad_norm": 0.7778462171554565,
      "learning_rate": 7.206070860893196e-05,
      "loss": 2.2131,
      "step": 5450
    },
    {
      "epoch": 0.8398707891093677,
      "grad_norm": 0.9634210467338562,
      "learning_rate": 7.200943444598267e-05,
      "loss": 2.227,
      "step": 5460
    },
    {
      "epoch": 0.8414090139978465,
      "grad_norm": 0.960573136806488,
      "learning_rate": 7.195816028303338e-05,
      "loss": 2.2048,
      "step": 5470
    },
    {
      "epoch": 0.8429472388863252,
      "grad_norm": 0.995637834072113,
      "learning_rate": 7.190688612008409e-05,
      "loss": 2.2041,
      "step": 5480
    },
    {
      "epoch": 0.8444854637748038,
      "grad_norm": 0.9745773673057556,
      "learning_rate": 7.185561195713481e-05,
      "loss": 2.2385,
      "step": 5490
    },
    {
      "epoch": 0.8460236886632826,
      "grad_norm": 1.005265712738037,
      "learning_rate": 7.180433779418552e-05,
      "loss": 2.2298,
      "step": 5500
    },
    {
      "epoch": 0.8475619135517612,
      "grad_norm": 1.0382027626037598,
      "learning_rate": 7.175306363123623e-05,
      "loss": 2.3451,
      "step": 5510
    },
    {
      "epoch": 0.84910013844024,
      "grad_norm": 1.2968811988830566,
      "learning_rate": 7.170178946828692e-05,
      "loss": 2.1005,
      "step": 5520
    },
    {
      "epoch": 0.8506383633287187,
      "grad_norm": 0.9986342787742615,
      "learning_rate": 7.165051530533765e-05,
      "loss": 2.2197,
      "step": 5530
    },
    {
      "epoch": 0.8521765882171973,
      "grad_norm": 0.8931381106376648,
      "learning_rate": 7.159924114238836e-05,
      "loss": 2.4121,
      "step": 5540
    },
    {
      "epoch": 0.8537148131056761,
      "grad_norm": 0.8220108151435852,
      "learning_rate": 7.154796697943906e-05,
      "loss": 2.2852,
      "step": 5550
    },
    {
      "epoch": 0.8552530379941548,
      "grad_norm": 0.7097431421279907,
      "learning_rate": 7.149669281648977e-05,
      "loss": 2.2439,
      "step": 5560
    },
    {
      "epoch": 0.8567912628826334,
      "grad_norm": 0.8796679973602295,
      "learning_rate": 7.144541865354048e-05,
      "loss": 2.2442,
      "step": 5570
    },
    {
      "epoch": 0.8583294877711122,
      "grad_norm": 1.0420113801956177,
      "learning_rate": 7.139414449059119e-05,
      "loss": 2.2996,
      "step": 5580
    },
    {
      "epoch": 0.8598677126595908,
      "grad_norm": 0.9017590284347534,
      "learning_rate": 7.134287032764191e-05,
      "loss": 2.3176,
      "step": 5590
    },
    {
      "epoch": 0.8614059375480695,
      "grad_norm": 1.0023633241653442,
      "learning_rate": 7.129159616469262e-05,
      "loss": 2.2086,
      "step": 5600
    },
    {
      "epoch": 0.8629441624365483,
      "grad_norm": 1.1581523418426514,
      "learning_rate": 7.124032200174332e-05,
      "loss": 2.2061,
      "step": 5610
    },
    {
      "epoch": 0.8644823873250269,
      "grad_norm": 0.7982566356658936,
      "learning_rate": 7.118904783879403e-05,
      "loss": 2.2175,
      "step": 5620
    },
    {
      "epoch": 0.8660206122135056,
      "grad_norm": 0.8286187648773193,
      "learning_rate": 7.113777367584474e-05,
      "loss": 2.1998,
      "step": 5630
    },
    {
      "epoch": 0.8675588371019843,
      "grad_norm": 1.0498437881469727,
      "learning_rate": 7.108649951289546e-05,
      "loss": 2.2441,
      "step": 5640
    },
    {
      "epoch": 0.869097061990463,
      "grad_norm": 0.9181168079376221,
      "learning_rate": 7.103522534994617e-05,
      "loss": 2.1805,
      "step": 5650
    },
    {
      "epoch": 0.8706352868789416,
      "grad_norm": 0.9713919758796692,
      "learning_rate": 7.098395118699688e-05,
      "loss": 2.3229,
      "step": 5660
    },
    {
      "epoch": 0.8721735117674204,
      "grad_norm": 1.0265237092971802,
      "learning_rate": 7.093267702404759e-05,
      "loss": 2.2746,
      "step": 5670
    },
    {
      "epoch": 0.8737117366558991,
      "grad_norm": 0.8737251162528992,
      "learning_rate": 7.08814028610983e-05,
      "loss": 2.203,
      "step": 5680
    },
    {
      "epoch": 0.8752499615443778,
      "grad_norm": 0.8156078457832336,
      "learning_rate": 7.0830128698149e-05,
      "loss": 2.3261,
      "step": 5690
    },
    {
      "epoch": 0.8767881864328565,
      "grad_norm": 0.7743782997131348,
      "learning_rate": 7.077885453519971e-05,
      "loss": 2.2545,
      "step": 5700
    },
    {
      "epoch": 0.8783264113213352,
      "grad_norm": 1.2242268323898315,
      "learning_rate": 7.072758037225042e-05,
      "loss": 2.2157,
      "step": 5710
    },
    {
      "epoch": 0.8798646362098139,
      "grad_norm": 1.1011817455291748,
      "learning_rate": 7.067630620930113e-05,
      "loss": 2.2289,
      "step": 5720
    },
    {
      "epoch": 0.8814028610982926,
      "grad_norm": 0.9632259011268616,
      "learning_rate": 7.062503204635184e-05,
      "loss": 2.1752,
      "step": 5730
    },
    {
      "epoch": 0.8829410859867712,
      "grad_norm": 1.1523116827011108,
      "learning_rate": 7.057375788340256e-05,
      "loss": 2.2177,
      "step": 5740
    },
    {
      "epoch": 0.88447931087525,
      "grad_norm": 1.3633785247802734,
      "learning_rate": 7.052248372045327e-05,
      "loss": 2.2051,
      "step": 5750
    },
    {
      "epoch": 0.8860175357637287,
      "grad_norm": 1.2254995107650757,
      "learning_rate": 7.047120955750398e-05,
      "loss": 2.3028,
      "step": 5760
    },
    {
      "epoch": 0.8875557606522073,
      "grad_norm": 0.8773002028465271,
      "learning_rate": 7.041993539455469e-05,
      "loss": 2.1646,
      "step": 5770
    },
    {
      "epoch": 0.8890939855406861,
      "grad_norm": 0.9160082936286926,
      "learning_rate": 7.036866123160539e-05,
      "loss": 2.152,
      "step": 5780
    },
    {
      "epoch": 0.8906322104291647,
      "grad_norm": 0.9669731259346008,
      "learning_rate": 7.031738706865611e-05,
      "loss": 2.2959,
      "step": 5790
    },
    {
      "epoch": 0.8921704353176434,
      "grad_norm": 1.0729905366897583,
      "learning_rate": 7.026611290570682e-05,
      "loss": 2.2025,
      "step": 5800
    },
    {
      "epoch": 0.8937086602061222,
      "grad_norm": 0.9462867379188538,
      "learning_rate": 7.021483874275753e-05,
      "loss": 2.2259,
      "step": 5810
    },
    {
      "epoch": 0.8952468850946008,
      "grad_norm": 1.0438424348831177,
      "learning_rate": 7.016356457980824e-05,
      "loss": 2.2253,
      "step": 5820
    },
    {
      "epoch": 0.8967851099830795,
      "grad_norm": 0.9640107750892639,
      "learning_rate": 7.011229041685895e-05,
      "loss": 2.2596,
      "step": 5830
    },
    {
      "epoch": 0.8983233348715582,
      "grad_norm": 1.0038121938705444,
      "learning_rate": 7.006101625390966e-05,
      "loss": 2.1998,
      "step": 5840
    },
    {
      "epoch": 0.8998615597600369,
      "grad_norm": 0.9922749996185303,
      "learning_rate": 7.000974209096038e-05,
      "loss": 2.2346,
      "step": 5850
    },
    {
      "epoch": 0.9013997846485157,
      "grad_norm": 1.0703380107879639,
      "learning_rate": 6.995846792801107e-05,
      "loss": 2.2383,
      "step": 5860
    },
    {
      "epoch": 0.9029380095369943,
      "grad_norm": 0.9439657330513,
      "learning_rate": 6.990719376506178e-05,
      "loss": 2.2418,
      "step": 5870
    },
    {
      "epoch": 0.904476234425473,
      "grad_norm": 1.311553716659546,
      "learning_rate": 6.985591960211249e-05,
      "loss": 2.2657,
      "step": 5880
    },
    {
      "epoch": 0.9060144593139517,
      "grad_norm": 0.8907186985015869,
      "learning_rate": 6.980464543916321e-05,
      "loss": 2.1981,
      "step": 5890
    },
    {
      "epoch": 0.9075526842024304,
      "grad_norm": 0.9506505131721497,
      "learning_rate": 6.975337127621392e-05,
      "loss": 2.1985,
      "step": 5900
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 0.879865288734436,
      "learning_rate": 6.970209711326463e-05,
      "loss": 2.2871,
      "step": 5910
    },
    {
      "epoch": 0.9106291339793878,
      "grad_norm": 0.9533790349960327,
      "learning_rate": 6.965082295031534e-05,
      "loss": 2.2332,
      "step": 5920
    },
    {
      "epoch": 0.9121673588678665,
      "grad_norm": 0.7192929983139038,
      "learning_rate": 6.959954878736605e-05,
      "loss": 2.2935,
      "step": 5930
    },
    {
      "epoch": 0.9137055837563451,
      "grad_norm": 0.849898636341095,
      "learning_rate": 6.954827462441676e-05,
      "loss": 2.2881,
      "step": 5940
    },
    {
      "epoch": 0.9152438086448239,
      "grad_norm": 1.002225637435913,
      "learning_rate": 6.949700046146747e-05,
      "loss": 2.1494,
      "step": 5950
    },
    {
      "epoch": 0.9167820335333026,
      "grad_norm": 1.1923339366912842,
      "learning_rate": 6.944572629851818e-05,
      "loss": 2.2591,
      "step": 5960
    },
    {
      "epoch": 0.9183202584217812,
      "grad_norm": 0.962456464767456,
      "learning_rate": 6.939445213556889e-05,
      "loss": 2.2177,
      "step": 5970
    },
    {
      "epoch": 0.91985848331026,
      "grad_norm": 1.1654248237609863,
      "learning_rate": 6.93431779726196e-05,
      "loss": 2.2075,
      "step": 5980
    },
    {
      "epoch": 0.9213967081987386,
      "grad_norm": 0.8172051906585693,
      "learning_rate": 6.92919038096703e-05,
      "loss": 2.1862,
      "step": 5990
    },
    {
      "epoch": 0.9229349330872173,
      "grad_norm": 0.9794129729270935,
      "learning_rate": 6.924062964672103e-05,
      "loss": 2.4075,
      "step": 6000
    }
  ],
  "logging_steps": 10,
  "max_steps": 19503,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2661605531648e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
