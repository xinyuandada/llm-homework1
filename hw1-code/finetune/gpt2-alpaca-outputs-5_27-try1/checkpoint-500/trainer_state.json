{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.07691124442393478,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0015382248884786955,
      "grad_norm": 0.7800440192222595,
      "learning_rate": 9.995385325334565e-05,
      "loss": 3.3764,
      "step": 10
    },
    {
      "epoch": 0.003076449776957391,
      "grad_norm": 0.7170557975769043,
      "learning_rate": 9.990257909039636e-05,
      "loss": 3.2895,
      "step": 20
    },
    {
      "epoch": 0.0046146746654360865,
      "grad_norm": 0.7733101844787598,
      "learning_rate": 9.985130492744707e-05,
      "loss": 3.2437,
      "step": 30
    },
    {
      "epoch": 0.006152899553914782,
      "grad_norm": 1.1588221788406372,
      "learning_rate": 9.980003076449777e-05,
      "loss": 3.0131,
      "step": 40
    },
    {
      "epoch": 0.007691124442393478,
      "grad_norm": 1.1910779476165771,
      "learning_rate": 9.974875660154848e-05,
      "loss": 2.8109,
      "step": 50
    },
    {
      "epoch": 0.009229349330872173,
      "grad_norm": 0.9716565012931824,
      "learning_rate": 9.969748243859919e-05,
      "loss": 2.7559,
      "step": 60
    },
    {
      "epoch": 0.01076757421935087,
      "grad_norm": 1.3204234838485718,
      "learning_rate": 9.96462082756499e-05,
      "loss": 2.9574,
      "step": 70
    },
    {
      "epoch": 0.012305799107829564,
      "grad_norm": 1.1385749578475952,
      "learning_rate": 9.959493411270061e-05,
      "loss": 2.6185,
      "step": 80
    },
    {
      "epoch": 0.01384402399630826,
      "grad_norm": 1.5976508855819702,
      "learning_rate": 9.954365994975132e-05,
      "loss": 2.7861,
      "step": 90
    },
    {
      "epoch": 0.015382248884786957,
      "grad_norm": 1.2703982591629028,
      "learning_rate": 9.949238578680203e-05,
      "loss": 2.7095,
      "step": 100
    },
    {
      "epoch": 0.01692047377326565,
      "grad_norm": 0.9696293473243713,
      "learning_rate": 9.944111162385275e-05,
      "loss": 2.6845,
      "step": 110
    },
    {
      "epoch": 0.018458698661744346,
      "grad_norm": 1.0070174932479858,
      "learning_rate": 9.938983746090346e-05,
      "loss": 2.5992,
      "step": 120
    },
    {
      "epoch": 0.019996923550223044,
      "grad_norm": 0.7789586186408997,
      "learning_rate": 9.933856329795417e-05,
      "loss": 2.5619,
      "step": 130
    },
    {
      "epoch": 0.02153514843870174,
      "grad_norm": 0.9720857739448547,
      "learning_rate": 9.928728913500488e-05,
      "loss": 2.5737,
      "step": 140
    },
    {
      "epoch": 0.023073373327180433,
      "grad_norm": 0.9559718370437622,
      "learning_rate": 9.923601497205559e-05,
      "loss": 2.582,
      "step": 150
    },
    {
      "epoch": 0.024611598215659128,
      "grad_norm": 1.2294028997421265,
      "learning_rate": 9.91847408091063e-05,
      "loss": 2.5172,
      "step": 160
    },
    {
      "epoch": 0.026149823104137826,
      "grad_norm": 0.8206753730773926,
      "learning_rate": 9.9133466646157e-05,
      "loss": 2.6148,
      "step": 170
    },
    {
      "epoch": 0.02768804799261652,
      "grad_norm": 1.6609854698181152,
      "learning_rate": 9.908219248320772e-05,
      "loss": 2.5482,
      "step": 180
    },
    {
      "epoch": 0.029226272881095215,
      "grad_norm": 0.9564527869224548,
      "learning_rate": 9.903091832025842e-05,
      "loss": 2.5977,
      "step": 190
    },
    {
      "epoch": 0.030764497769573913,
      "grad_norm": 1.0379178524017334,
      "learning_rate": 9.897964415730913e-05,
      "loss": 2.6212,
      "step": 200
    },
    {
      "epoch": 0.032302722658052604,
      "grad_norm": 1.038809895515442,
      "learning_rate": 9.892836999435984e-05,
      "loss": 2.5757,
      "step": 210
    },
    {
      "epoch": 0.0338409475465313,
      "grad_norm": 1.1101423501968384,
      "learning_rate": 9.887709583141056e-05,
      "loss": 2.4347,
      "step": 220
    },
    {
      "epoch": 0.03537917243501,
      "grad_norm": 1.4410618543624878,
      "learning_rate": 9.882582166846127e-05,
      "loss": 2.451,
      "step": 230
    },
    {
      "epoch": 0.03691739732348869,
      "grad_norm": 1.5485572814941406,
      "learning_rate": 9.877454750551197e-05,
      "loss": 2.4091,
      "step": 240
    },
    {
      "epoch": 0.03845562221196739,
      "grad_norm": 0.8919523358345032,
      "learning_rate": 9.872327334256268e-05,
      "loss": 2.4517,
      "step": 250
    },
    {
      "epoch": 0.03999384710044609,
      "grad_norm": 1.5257225036621094,
      "learning_rate": 9.86719991796134e-05,
      "loss": 2.5079,
      "step": 260
    },
    {
      "epoch": 0.04153207198892478,
      "grad_norm": 1.1131129264831543,
      "learning_rate": 9.862072501666411e-05,
      "loss": 2.5233,
      "step": 270
    },
    {
      "epoch": 0.04307029687740348,
      "grad_norm": 1.0646756887435913,
      "learning_rate": 9.856945085371482e-05,
      "loss": 2.5011,
      "step": 280
    },
    {
      "epoch": 0.044608521765882175,
      "grad_norm": 0.9087584614753723,
      "learning_rate": 9.851817669076553e-05,
      "loss": 2.4325,
      "step": 290
    },
    {
      "epoch": 0.046146746654360866,
      "grad_norm": 0.9257020950317383,
      "learning_rate": 9.846690252781624e-05,
      "loss": 2.4766,
      "step": 300
    },
    {
      "epoch": 0.047684971542839565,
      "grad_norm": 1.2664592266082764,
      "learning_rate": 9.841562836486695e-05,
      "loss": 2.379,
      "step": 310
    },
    {
      "epoch": 0.049223196431318256,
      "grad_norm": 1.7497199773788452,
      "learning_rate": 9.836435420191767e-05,
      "loss": 2.497,
      "step": 320
    },
    {
      "epoch": 0.050761421319796954,
      "grad_norm": 1.0710874795913696,
      "learning_rate": 9.831308003896836e-05,
      "loss": 2.4277,
      "step": 330
    },
    {
      "epoch": 0.05229964620827565,
      "grad_norm": 1.1468404531478882,
      "learning_rate": 9.826180587601907e-05,
      "loss": 2.4062,
      "step": 340
    },
    {
      "epoch": 0.05383787109675434,
      "grad_norm": 0.9473360776901245,
      "learning_rate": 9.821053171306978e-05,
      "loss": 2.3603,
      "step": 350
    },
    {
      "epoch": 0.05537609598523304,
      "grad_norm": 0.9064487218856812,
      "learning_rate": 9.815925755012049e-05,
      "loss": 2.5071,
      "step": 360
    },
    {
      "epoch": 0.05691432087371174,
      "grad_norm": 1.2210891246795654,
      "learning_rate": 9.810798338717121e-05,
      "loss": 2.3493,
      "step": 370
    },
    {
      "epoch": 0.05845254576219043,
      "grad_norm": 1.030822992324829,
      "learning_rate": 9.805670922422192e-05,
      "loss": 2.5064,
      "step": 380
    },
    {
      "epoch": 0.05999077065066913,
      "grad_norm": 1.2741059064865112,
      "learning_rate": 9.800543506127263e-05,
      "loss": 2.4764,
      "step": 390
    },
    {
      "epoch": 0.06152899553914783,
      "grad_norm": 1.203805685043335,
      "learning_rate": 9.795416089832334e-05,
      "loss": 2.447,
      "step": 400
    },
    {
      "epoch": 0.06306722042762652,
      "grad_norm": 1.0742758512496948,
      "learning_rate": 9.790288673537404e-05,
      "loss": 2.427,
      "step": 410
    },
    {
      "epoch": 0.06460544531610521,
      "grad_norm": 1.02286958694458,
      "learning_rate": 9.785161257242476e-05,
      "loss": 2.4394,
      "step": 420
    },
    {
      "epoch": 0.06614367020458391,
      "grad_norm": 0.9090739488601685,
      "learning_rate": 9.780033840947547e-05,
      "loss": 2.4173,
      "step": 430
    },
    {
      "epoch": 0.0676818950930626,
      "grad_norm": 1.149408221244812,
      "learning_rate": 9.774906424652618e-05,
      "loss": 2.456,
      "step": 440
    },
    {
      "epoch": 0.0692201199815413,
      "grad_norm": 0.963049590587616,
      "learning_rate": 9.769779008357689e-05,
      "loss": 2.3834,
      "step": 450
    },
    {
      "epoch": 0.07075834487002,
      "grad_norm": 0.9821059107780457,
      "learning_rate": 9.76465159206276e-05,
      "loss": 2.4565,
      "step": 460
    },
    {
      "epoch": 0.0722965697584987,
      "grad_norm": 1.0546011924743652,
      "learning_rate": 9.759524175767832e-05,
      "loss": 2.396,
      "step": 470
    },
    {
      "epoch": 0.07383479464697738,
      "grad_norm": 1.0994268655776978,
      "learning_rate": 9.754396759472903e-05,
      "loss": 2.4549,
      "step": 480
    },
    {
      "epoch": 0.07537301953545608,
      "grad_norm": 0.8789143562316895,
      "learning_rate": 9.749269343177974e-05,
      "loss": 2.4605,
      "step": 490
    },
    {
      "epoch": 0.07691124442393478,
      "grad_norm": 0.9876823425292969,
      "learning_rate": 9.744141926883043e-05,
      "loss": 2.4503,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 19503,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1055133794304000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
