{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.3845562221196739,
  "eval_steps": 500,
  "global_step": 2500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0015382248884786955,
      "grad_norm": 0.7800440192222595,
      "learning_rate": 9.995385325334565e-05,
      "loss": 3.3764,
      "step": 10
    },
    {
      "epoch": 0.003076449776957391,
      "grad_norm": 0.7170557975769043,
      "learning_rate": 9.990257909039636e-05,
      "loss": 3.2895,
      "step": 20
    },
    {
      "epoch": 0.0046146746654360865,
      "grad_norm": 0.7733101844787598,
      "learning_rate": 9.985130492744707e-05,
      "loss": 3.2437,
      "step": 30
    },
    {
      "epoch": 0.006152899553914782,
      "grad_norm": 1.1588221788406372,
      "learning_rate": 9.980003076449777e-05,
      "loss": 3.0131,
      "step": 40
    },
    {
      "epoch": 0.007691124442393478,
      "grad_norm": 1.1910779476165771,
      "learning_rate": 9.974875660154848e-05,
      "loss": 2.8109,
      "step": 50
    },
    {
      "epoch": 0.009229349330872173,
      "grad_norm": 0.9716565012931824,
      "learning_rate": 9.969748243859919e-05,
      "loss": 2.7559,
      "step": 60
    },
    {
      "epoch": 0.01076757421935087,
      "grad_norm": 1.3204234838485718,
      "learning_rate": 9.96462082756499e-05,
      "loss": 2.9574,
      "step": 70
    },
    {
      "epoch": 0.012305799107829564,
      "grad_norm": 1.1385749578475952,
      "learning_rate": 9.959493411270061e-05,
      "loss": 2.6185,
      "step": 80
    },
    {
      "epoch": 0.01384402399630826,
      "grad_norm": 1.5976508855819702,
      "learning_rate": 9.954365994975132e-05,
      "loss": 2.7861,
      "step": 90
    },
    {
      "epoch": 0.015382248884786957,
      "grad_norm": 1.2703982591629028,
      "learning_rate": 9.949238578680203e-05,
      "loss": 2.7095,
      "step": 100
    },
    {
      "epoch": 0.01692047377326565,
      "grad_norm": 0.9696293473243713,
      "learning_rate": 9.944111162385275e-05,
      "loss": 2.6845,
      "step": 110
    },
    {
      "epoch": 0.018458698661744346,
      "grad_norm": 1.0070174932479858,
      "learning_rate": 9.938983746090346e-05,
      "loss": 2.5992,
      "step": 120
    },
    {
      "epoch": 0.019996923550223044,
      "grad_norm": 0.7789586186408997,
      "learning_rate": 9.933856329795417e-05,
      "loss": 2.5619,
      "step": 130
    },
    {
      "epoch": 0.02153514843870174,
      "grad_norm": 0.9720857739448547,
      "learning_rate": 9.928728913500488e-05,
      "loss": 2.5737,
      "step": 140
    },
    {
      "epoch": 0.023073373327180433,
      "grad_norm": 0.9559718370437622,
      "learning_rate": 9.923601497205559e-05,
      "loss": 2.582,
      "step": 150
    },
    {
      "epoch": 0.024611598215659128,
      "grad_norm": 1.2294028997421265,
      "learning_rate": 9.91847408091063e-05,
      "loss": 2.5172,
      "step": 160
    },
    {
      "epoch": 0.026149823104137826,
      "grad_norm": 0.8206753730773926,
      "learning_rate": 9.9133466646157e-05,
      "loss": 2.6148,
      "step": 170
    },
    {
      "epoch": 0.02768804799261652,
      "grad_norm": 1.6609854698181152,
      "learning_rate": 9.908219248320772e-05,
      "loss": 2.5482,
      "step": 180
    },
    {
      "epoch": 0.029226272881095215,
      "grad_norm": 0.9564527869224548,
      "learning_rate": 9.903091832025842e-05,
      "loss": 2.5977,
      "step": 190
    },
    {
      "epoch": 0.030764497769573913,
      "grad_norm": 1.0379178524017334,
      "learning_rate": 9.897964415730913e-05,
      "loss": 2.6212,
      "step": 200
    },
    {
      "epoch": 0.032302722658052604,
      "grad_norm": 1.038809895515442,
      "learning_rate": 9.892836999435984e-05,
      "loss": 2.5757,
      "step": 210
    },
    {
      "epoch": 0.0338409475465313,
      "grad_norm": 1.1101423501968384,
      "learning_rate": 9.887709583141056e-05,
      "loss": 2.4347,
      "step": 220
    },
    {
      "epoch": 0.03537917243501,
      "grad_norm": 1.4410618543624878,
      "learning_rate": 9.882582166846127e-05,
      "loss": 2.451,
      "step": 230
    },
    {
      "epoch": 0.03691739732348869,
      "grad_norm": 1.5485572814941406,
      "learning_rate": 9.877454750551197e-05,
      "loss": 2.4091,
      "step": 240
    },
    {
      "epoch": 0.03845562221196739,
      "grad_norm": 0.8919523358345032,
      "learning_rate": 9.872327334256268e-05,
      "loss": 2.4517,
      "step": 250
    },
    {
      "epoch": 0.03999384710044609,
      "grad_norm": 1.5257225036621094,
      "learning_rate": 9.86719991796134e-05,
      "loss": 2.5079,
      "step": 260
    },
    {
      "epoch": 0.04153207198892478,
      "grad_norm": 1.1131129264831543,
      "learning_rate": 9.862072501666411e-05,
      "loss": 2.5233,
      "step": 270
    },
    {
      "epoch": 0.04307029687740348,
      "grad_norm": 1.0646756887435913,
      "learning_rate": 9.856945085371482e-05,
      "loss": 2.5011,
      "step": 280
    },
    {
      "epoch": 0.044608521765882175,
      "grad_norm": 0.9087584614753723,
      "learning_rate": 9.851817669076553e-05,
      "loss": 2.4325,
      "step": 290
    },
    {
      "epoch": 0.046146746654360866,
      "grad_norm": 0.9257020950317383,
      "learning_rate": 9.846690252781624e-05,
      "loss": 2.4766,
      "step": 300
    },
    {
      "epoch": 0.047684971542839565,
      "grad_norm": 1.2664592266082764,
      "learning_rate": 9.841562836486695e-05,
      "loss": 2.379,
      "step": 310
    },
    {
      "epoch": 0.049223196431318256,
      "grad_norm": 1.7497199773788452,
      "learning_rate": 9.836435420191767e-05,
      "loss": 2.497,
      "step": 320
    },
    {
      "epoch": 0.050761421319796954,
      "grad_norm": 1.0710874795913696,
      "learning_rate": 9.831308003896836e-05,
      "loss": 2.4277,
      "step": 330
    },
    {
      "epoch": 0.05229964620827565,
      "grad_norm": 1.1468404531478882,
      "learning_rate": 9.826180587601907e-05,
      "loss": 2.4062,
      "step": 340
    },
    {
      "epoch": 0.05383787109675434,
      "grad_norm": 0.9473360776901245,
      "learning_rate": 9.821053171306978e-05,
      "loss": 2.3603,
      "step": 350
    },
    {
      "epoch": 0.05537609598523304,
      "grad_norm": 0.9064487218856812,
      "learning_rate": 9.815925755012049e-05,
      "loss": 2.5071,
      "step": 360
    },
    {
      "epoch": 0.05691432087371174,
      "grad_norm": 1.2210891246795654,
      "learning_rate": 9.810798338717121e-05,
      "loss": 2.3493,
      "step": 370
    },
    {
      "epoch": 0.05845254576219043,
      "grad_norm": 1.030822992324829,
      "learning_rate": 9.805670922422192e-05,
      "loss": 2.5064,
      "step": 380
    },
    {
      "epoch": 0.05999077065066913,
      "grad_norm": 1.2741059064865112,
      "learning_rate": 9.800543506127263e-05,
      "loss": 2.4764,
      "step": 390
    },
    {
      "epoch": 0.06152899553914783,
      "grad_norm": 1.203805685043335,
      "learning_rate": 9.795416089832334e-05,
      "loss": 2.447,
      "step": 400
    },
    {
      "epoch": 0.06306722042762652,
      "grad_norm": 1.0742758512496948,
      "learning_rate": 9.790288673537404e-05,
      "loss": 2.427,
      "step": 410
    },
    {
      "epoch": 0.06460544531610521,
      "grad_norm": 1.02286958694458,
      "learning_rate": 9.785161257242476e-05,
      "loss": 2.4394,
      "step": 420
    },
    {
      "epoch": 0.06614367020458391,
      "grad_norm": 0.9090739488601685,
      "learning_rate": 9.780033840947547e-05,
      "loss": 2.4173,
      "step": 430
    },
    {
      "epoch": 0.0676818950930626,
      "grad_norm": 1.149408221244812,
      "learning_rate": 9.774906424652618e-05,
      "loss": 2.456,
      "step": 440
    },
    {
      "epoch": 0.0692201199815413,
      "grad_norm": 0.963049590587616,
      "learning_rate": 9.769779008357689e-05,
      "loss": 2.3834,
      "step": 450
    },
    {
      "epoch": 0.07075834487002,
      "grad_norm": 0.9821059107780457,
      "learning_rate": 9.76465159206276e-05,
      "loss": 2.4565,
      "step": 460
    },
    {
      "epoch": 0.0722965697584987,
      "grad_norm": 1.0546011924743652,
      "learning_rate": 9.759524175767832e-05,
      "loss": 2.396,
      "step": 470
    },
    {
      "epoch": 0.07383479464697738,
      "grad_norm": 1.0994268655776978,
      "learning_rate": 9.754396759472903e-05,
      "loss": 2.4549,
      "step": 480
    },
    {
      "epoch": 0.07537301953545608,
      "grad_norm": 0.8789143562316895,
      "learning_rate": 9.749269343177974e-05,
      "loss": 2.4605,
      "step": 490
    },
    {
      "epoch": 0.07691124442393478,
      "grad_norm": 0.9876823425292969,
      "learning_rate": 9.744141926883043e-05,
      "loss": 2.4503,
      "step": 500
    },
    {
      "epoch": 0.07844946931241348,
      "grad_norm": 1.1950620412826538,
      "learning_rate": 9.739014510588114e-05,
      "loss": 2.5059,
      "step": 510
    },
    {
      "epoch": 0.07998769420089218,
      "grad_norm": 1.1006996631622314,
      "learning_rate": 9.733887094293186e-05,
      "loss": 2.2882,
      "step": 520
    },
    {
      "epoch": 0.08152591908937086,
      "grad_norm": 0.9053552150726318,
      "learning_rate": 9.728759677998257e-05,
      "loss": 2.3396,
      "step": 530
    },
    {
      "epoch": 0.08306414397784956,
      "grad_norm": 1.1737337112426758,
      "learning_rate": 9.723632261703328e-05,
      "loss": 2.4247,
      "step": 540
    },
    {
      "epoch": 0.08460236886632826,
      "grad_norm": 0.8845342993736267,
      "learning_rate": 9.718504845408399e-05,
      "loss": 2.3835,
      "step": 550
    },
    {
      "epoch": 0.08614059375480695,
      "grad_norm": 1.0540077686309814,
      "learning_rate": 9.71337742911347e-05,
      "loss": 2.369,
      "step": 560
    },
    {
      "epoch": 0.08767881864328565,
      "grad_norm": 0.9919202923774719,
      "learning_rate": 9.708250012818541e-05,
      "loss": 2.4425,
      "step": 570
    },
    {
      "epoch": 0.08921704353176435,
      "grad_norm": 0.9196600914001465,
      "learning_rate": 9.703122596523612e-05,
      "loss": 2.3381,
      "step": 580
    },
    {
      "epoch": 0.09075526842024303,
      "grad_norm": 1.1251168251037598,
      "learning_rate": 9.697995180228683e-05,
      "loss": 2.3186,
      "step": 590
    },
    {
      "epoch": 0.09229349330872173,
      "grad_norm": 1.3643468618392944,
      "learning_rate": 9.692867763933754e-05,
      "loss": 2.4726,
      "step": 600
    },
    {
      "epoch": 0.09383171819720043,
      "grad_norm": 0.8772892951965332,
      "learning_rate": 9.687740347638825e-05,
      "loss": 2.4736,
      "step": 610
    },
    {
      "epoch": 0.09536994308567913,
      "grad_norm": 1.061119556427002,
      "learning_rate": 9.682612931343897e-05,
      "loss": 2.4213,
      "step": 620
    },
    {
      "epoch": 0.09690816797415783,
      "grad_norm": 0.9421314597129822,
      "learning_rate": 9.677485515048968e-05,
      "loss": 2.4277,
      "step": 630
    },
    {
      "epoch": 0.09844639286263651,
      "grad_norm": 1.2146601676940918,
      "learning_rate": 9.672358098754039e-05,
      "loss": 2.2897,
      "step": 640
    },
    {
      "epoch": 0.09998461775111521,
      "grad_norm": 1.2775753736495972,
      "learning_rate": 9.66723068245911e-05,
      "loss": 2.4684,
      "step": 650
    },
    {
      "epoch": 0.10152284263959391,
      "grad_norm": 1.0711489915847778,
      "learning_rate": 9.66210326616418e-05,
      "loss": 2.3954,
      "step": 660
    },
    {
      "epoch": 0.1030610675280726,
      "grad_norm": 0.9492761492729187,
      "learning_rate": 9.656975849869251e-05,
      "loss": 2.3824,
      "step": 670
    },
    {
      "epoch": 0.1045992924165513,
      "grad_norm": 0.8662605285644531,
      "learning_rate": 9.651848433574322e-05,
      "loss": 2.2737,
      "step": 680
    },
    {
      "epoch": 0.10613751730503,
      "grad_norm": 0.9089555740356445,
      "learning_rate": 9.646721017279393e-05,
      "loss": 2.4527,
      "step": 690
    },
    {
      "epoch": 0.10767574219350869,
      "grad_norm": 0.8828738331794739,
      "learning_rate": 9.641593600984464e-05,
      "loss": 2.3143,
      "step": 700
    },
    {
      "epoch": 0.10921396708198738,
      "grad_norm": 0.8621166944503784,
      "learning_rate": 9.636466184689535e-05,
      "loss": 2.2994,
      "step": 710
    },
    {
      "epoch": 0.11075219197046608,
      "grad_norm": 0.9188641309738159,
      "learning_rate": 9.631338768394606e-05,
      "loss": 2.3995,
      "step": 720
    },
    {
      "epoch": 0.11229041685894478,
      "grad_norm": 0.9558343291282654,
      "learning_rate": 9.626211352099678e-05,
      "loss": 2.3769,
      "step": 730
    },
    {
      "epoch": 0.11382864174742348,
      "grad_norm": 0.8890336751937866,
      "learning_rate": 9.621083935804749e-05,
      "loss": 2.345,
      "step": 740
    },
    {
      "epoch": 0.11536686663590216,
      "grad_norm": 1.3892899751663208,
      "learning_rate": 9.61595651950982e-05,
      "loss": 2.3247,
      "step": 750
    },
    {
      "epoch": 0.11690509152438086,
      "grad_norm": 0.9079137444496155,
      "learning_rate": 9.61082910321489e-05,
      "loss": 2.5095,
      "step": 760
    },
    {
      "epoch": 0.11844331641285956,
      "grad_norm": 0.9309729933738708,
      "learning_rate": 9.60570168691996e-05,
      "loss": 2.3357,
      "step": 770
    },
    {
      "epoch": 0.11998154130133826,
      "grad_norm": 1.0791698694229126,
      "learning_rate": 9.600574270625033e-05,
      "loss": 2.3941,
      "step": 780
    },
    {
      "epoch": 0.12151976618981696,
      "grad_norm": 0.9481079578399658,
      "learning_rate": 9.595446854330104e-05,
      "loss": 2.3263,
      "step": 790
    },
    {
      "epoch": 0.12305799107829565,
      "grad_norm": 1.384405255317688,
      "learning_rate": 9.590319438035175e-05,
      "loss": 2.3435,
      "step": 800
    },
    {
      "epoch": 0.12459621596677434,
      "grad_norm": 0.9731020927429199,
      "learning_rate": 9.585192021740246e-05,
      "loss": 2.3627,
      "step": 810
    },
    {
      "epoch": 0.12613444085525305,
      "grad_norm": 0.7296550869941711,
      "learning_rate": 9.580064605445316e-05,
      "loss": 2.2322,
      "step": 820
    },
    {
      "epoch": 0.12767266574373173,
      "grad_norm": 1.0827419757843018,
      "learning_rate": 9.574937189150389e-05,
      "loss": 2.4777,
      "step": 830
    },
    {
      "epoch": 0.12921089063221042,
      "grad_norm": 0.99042809009552,
      "learning_rate": 9.569809772855458e-05,
      "loss": 2.4005,
      "step": 840
    },
    {
      "epoch": 0.13074911552068913,
      "grad_norm": 1.324620246887207,
      "learning_rate": 9.564682356560529e-05,
      "loss": 2.4839,
      "step": 850
    },
    {
      "epoch": 0.13228734040916781,
      "grad_norm": 1.4613444805145264,
      "learning_rate": 9.5595549402656e-05,
      "loss": 2.4002,
      "step": 860
    },
    {
      "epoch": 0.13382556529764653,
      "grad_norm": 0.9288026094436646,
      "learning_rate": 9.554427523970671e-05,
      "loss": 2.3541,
      "step": 870
    },
    {
      "epoch": 0.1353637901861252,
      "grad_norm": 1.129841685295105,
      "learning_rate": 9.549300107675743e-05,
      "loss": 2.3574,
      "step": 880
    },
    {
      "epoch": 0.1369020150746039,
      "grad_norm": 0.8787457346916199,
      "learning_rate": 9.544172691380814e-05,
      "loss": 2.3814,
      "step": 890
    },
    {
      "epoch": 0.1384402399630826,
      "grad_norm": 0.9640584588050842,
      "learning_rate": 9.539045275085885e-05,
      "loss": 2.3224,
      "step": 900
    },
    {
      "epoch": 0.1399784648515613,
      "grad_norm": 1.1772041320800781,
      "learning_rate": 9.533917858790956e-05,
      "loss": 2.3084,
      "step": 910
    },
    {
      "epoch": 0.14151668974004,
      "grad_norm": 0.8222691416740417,
      "learning_rate": 9.528790442496027e-05,
      "loss": 2.4192,
      "step": 920
    },
    {
      "epoch": 0.1430549146285187,
      "grad_norm": 0.8213545680046082,
      "learning_rate": 9.523663026201098e-05,
      "loss": 2.3573,
      "step": 930
    },
    {
      "epoch": 0.1445931395169974,
      "grad_norm": 1.1404590606689453,
      "learning_rate": 9.518535609906169e-05,
      "loss": 2.3049,
      "step": 940
    },
    {
      "epoch": 0.14613136440547608,
      "grad_norm": 1.1463240385055542,
      "learning_rate": 9.51340819361124e-05,
      "loss": 2.4483,
      "step": 950
    },
    {
      "epoch": 0.14766958929395477,
      "grad_norm": 1.2217503786087036,
      "learning_rate": 9.50828077731631e-05,
      "loss": 2.4451,
      "step": 960
    },
    {
      "epoch": 0.14920781418243348,
      "grad_norm": 0.8242997527122498,
      "learning_rate": 9.503153361021381e-05,
      "loss": 2.3317,
      "step": 970
    },
    {
      "epoch": 0.15074603907091216,
      "grad_norm": 1.1569207906723022,
      "learning_rate": 9.498025944726452e-05,
      "loss": 2.2817,
      "step": 980
    },
    {
      "epoch": 0.15228426395939088,
      "grad_norm": 1.1216130256652832,
      "learning_rate": 9.492898528431525e-05,
      "loss": 2.3543,
      "step": 990
    },
    {
      "epoch": 0.15382248884786956,
      "grad_norm": 1.131046175956726,
      "learning_rate": 9.487771112136596e-05,
      "loss": 2.3527,
      "step": 1000
    },
    {
      "epoch": 0.15536071373634824,
      "grad_norm": 1.2182101011276245,
      "learning_rate": 9.482643695841665e-05,
      "loss": 2.2678,
      "step": 1010
    },
    {
      "epoch": 0.15689893862482696,
      "grad_norm": 0.9577516317367554,
      "learning_rate": 9.477516279546736e-05,
      "loss": 2.4039,
      "step": 1020
    },
    {
      "epoch": 0.15843716351330564,
      "grad_norm": 1.0458829402923584,
      "learning_rate": 9.472388863251808e-05,
      "loss": 2.413,
      "step": 1030
    },
    {
      "epoch": 0.15997538840178435,
      "grad_norm": 0.9187437891960144,
      "learning_rate": 9.467261446956879e-05,
      "loss": 2.3664,
      "step": 1040
    },
    {
      "epoch": 0.16151361329026304,
      "grad_norm": 0.829723060131073,
      "learning_rate": 9.46213403066195e-05,
      "loss": 2.3837,
      "step": 1050
    },
    {
      "epoch": 0.16305183817874172,
      "grad_norm": 1.2389100790023804,
      "learning_rate": 9.457006614367021e-05,
      "loss": 2.3635,
      "step": 1060
    },
    {
      "epoch": 0.16459006306722043,
      "grad_norm": 1.0236015319824219,
      "learning_rate": 9.451879198072092e-05,
      "loss": 2.2544,
      "step": 1070
    },
    {
      "epoch": 0.16612828795569912,
      "grad_norm": 0.8570135831832886,
      "learning_rate": 9.446751781777163e-05,
      "loss": 2.3395,
      "step": 1080
    },
    {
      "epoch": 0.16766651284417783,
      "grad_norm": 0.9625948071479797,
      "learning_rate": 9.441624365482235e-05,
      "loss": 2.3859,
      "step": 1090
    },
    {
      "epoch": 0.1692047377326565,
      "grad_norm": 0.89539635181427,
      "learning_rate": 9.436496949187305e-05,
      "loss": 2.3562,
      "step": 1100
    },
    {
      "epoch": 0.1707429626211352,
      "grad_norm": 0.9785100221633911,
      "learning_rate": 9.431369532892376e-05,
      "loss": 2.2446,
      "step": 1110
    },
    {
      "epoch": 0.1722811875096139,
      "grad_norm": 1.1737624406814575,
      "learning_rate": 9.426242116597446e-05,
      "loss": 2.3936,
      "step": 1120
    },
    {
      "epoch": 0.1738194123980926,
      "grad_norm": 0.9451086521148682,
      "learning_rate": 9.421114700302517e-05,
      "loss": 2.4288,
      "step": 1130
    },
    {
      "epoch": 0.1753576372865713,
      "grad_norm": 0.8831786513328552,
      "learning_rate": 9.41598728400759e-05,
      "loss": 2.3756,
      "step": 1140
    },
    {
      "epoch": 0.17689586217505,
      "grad_norm": 1.3798778057098389,
      "learning_rate": 9.41085986771266e-05,
      "loss": 2.482,
      "step": 1150
    },
    {
      "epoch": 0.1784340870635287,
      "grad_norm": 0.9072500467300415,
      "learning_rate": 9.405732451417731e-05,
      "loss": 2.2366,
      "step": 1160
    },
    {
      "epoch": 0.17997231195200739,
      "grad_norm": 0.851820707321167,
      "learning_rate": 9.400605035122802e-05,
      "loss": 2.2708,
      "step": 1170
    },
    {
      "epoch": 0.18151053684048607,
      "grad_norm": 0.9339284300804138,
      "learning_rate": 9.395477618827873e-05,
      "loss": 2.268,
      "step": 1180
    },
    {
      "epoch": 0.18304876172896478,
      "grad_norm": 0.8741077184677124,
      "learning_rate": 9.390350202532944e-05,
      "loss": 2.3972,
      "step": 1190
    },
    {
      "epoch": 0.18458698661744347,
      "grad_norm": 1.1137354373931885,
      "learning_rate": 9.385222786238015e-05,
      "loss": 2.2709,
      "step": 1200
    },
    {
      "epoch": 0.18612521150592218,
      "grad_norm": 0.8969918489456177,
      "learning_rate": 9.380095369943086e-05,
      "loss": 2.3409,
      "step": 1210
    },
    {
      "epoch": 0.18766343639440086,
      "grad_norm": 1.399888515472412,
      "learning_rate": 9.374967953648157e-05,
      "loss": 2.356,
      "step": 1220
    },
    {
      "epoch": 0.18920166128287955,
      "grad_norm": 1.1646440029144287,
      "learning_rate": 9.369840537353228e-05,
      "loss": 2.3076,
      "step": 1230
    },
    {
      "epoch": 0.19073988617135826,
      "grad_norm": 1.1363041400909424,
      "learning_rate": 9.3647131210583e-05,
      "loss": 2.3777,
      "step": 1240
    },
    {
      "epoch": 0.19227811105983694,
      "grad_norm": 1.016471266746521,
      "learning_rate": 9.359585704763371e-05,
      "loss": 2.3759,
      "step": 1250
    },
    {
      "epoch": 0.19381633594831565,
      "grad_norm": 0.8463709950447083,
      "learning_rate": 9.354458288468442e-05,
      "loss": 2.2938,
      "step": 1260
    },
    {
      "epoch": 0.19535456083679434,
      "grad_norm": 1.0321208238601685,
      "learning_rate": 9.349330872173511e-05,
      "loss": 2.3482,
      "step": 1270
    },
    {
      "epoch": 0.19689278572527302,
      "grad_norm": 0.801830530166626,
      "learning_rate": 9.344203455878582e-05,
      "loss": 2.2615,
      "step": 1280
    },
    {
      "epoch": 0.19843101061375173,
      "grad_norm": 0.9908499121665955,
      "learning_rate": 9.339076039583655e-05,
      "loss": 2.2918,
      "step": 1290
    },
    {
      "epoch": 0.19996923550223042,
      "grad_norm": 0.9015299081802368,
      "learning_rate": 9.333948623288725e-05,
      "loss": 2.3913,
      "step": 1300
    },
    {
      "epoch": 0.20150746039070913,
      "grad_norm": 0.8517335653305054,
      "learning_rate": 9.328821206993796e-05,
      "loss": 2.3604,
      "step": 1310
    },
    {
      "epoch": 0.20304568527918782,
      "grad_norm": 0.7576839923858643,
      "learning_rate": 9.323693790698867e-05,
      "loss": 2.2648,
      "step": 1320
    },
    {
      "epoch": 0.2045839101676665,
      "grad_norm": 1.0572640895843506,
      "learning_rate": 9.318566374403938e-05,
      "loss": 2.3066,
      "step": 1330
    },
    {
      "epoch": 0.2061221350561452,
      "grad_norm": 1.2618391513824463,
      "learning_rate": 9.313438958109009e-05,
      "loss": 2.4479,
      "step": 1340
    },
    {
      "epoch": 0.2076603599446239,
      "grad_norm": 0.9082226753234863,
      "learning_rate": 9.30831154181408e-05,
      "loss": 2.319,
      "step": 1350
    },
    {
      "epoch": 0.2091985848331026,
      "grad_norm": 1.137063980102539,
      "learning_rate": 9.303184125519151e-05,
      "loss": 2.3538,
      "step": 1360
    },
    {
      "epoch": 0.2107368097215813,
      "grad_norm": 1.2156848907470703,
      "learning_rate": 9.298056709224222e-05,
      "loss": 2.3672,
      "step": 1370
    },
    {
      "epoch": 0.21227503461006,
      "grad_norm": 1.0615837574005127,
      "learning_rate": 9.292929292929293e-05,
      "loss": 2.318,
      "step": 1380
    },
    {
      "epoch": 0.2138132594985387,
      "grad_norm": 0.7031446695327759,
      "learning_rate": 9.287801876634365e-05,
      "loss": 2.3754,
      "step": 1390
    },
    {
      "epoch": 0.21535148438701737,
      "grad_norm": 1.0792100429534912,
      "learning_rate": 9.282674460339436e-05,
      "loss": 2.3928,
      "step": 1400
    },
    {
      "epoch": 0.21688970927549608,
      "grad_norm": 0.9547038078308105,
      "learning_rate": 9.277547044044507e-05,
      "loss": 2.3834,
      "step": 1410
    },
    {
      "epoch": 0.21842793416397477,
      "grad_norm": 0.9081752896308899,
      "learning_rate": 9.272419627749578e-05,
      "loss": 2.366,
      "step": 1420
    },
    {
      "epoch": 0.21996615905245348,
      "grad_norm": 0.8674251437187195,
      "learning_rate": 9.267292211454649e-05,
      "loss": 2.3302,
      "step": 1430
    },
    {
      "epoch": 0.22150438394093216,
      "grad_norm": 0.7524937391281128,
      "learning_rate": 9.26216479515972e-05,
      "loss": 2.3265,
      "step": 1440
    },
    {
      "epoch": 0.22304260882941085,
      "grad_norm": 1.0890637636184692,
      "learning_rate": 9.25703737886479e-05,
      "loss": 2.4002,
      "step": 1450
    },
    {
      "epoch": 0.22458083371788956,
      "grad_norm": 0.9604703783988953,
      "learning_rate": 9.251909962569861e-05,
      "loss": 2.3997,
      "step": 1460
    },
    {
      "epoch": 0.22611905860636825,
      "grad_norm": 0.9587043523788452,
      "learning_rate": 9.246782546274932e-05,
      "loss": 2.1888,
      "step": 1470
    },
    {
      "epoch": 0.22765728349484696,
      "grad_norm": 0.8627868294715881,
      "learning_rate": 9.241655129980003e-05,
      "loss": 2.2271,
      "step": 1480
    },
    {
      "epoch": 0.22919550838332564,
      "grad_norm": 1.6658141613006592,
      "learning_rate": 9.236527713685074e-05,
      "loss": 2.3808,
      "step": 1490
    },
    {
      "epoch": 0.23073373327180433,
      "grad_norm": 0.8292087316513062,
      "learning_rate": 9.231400297390146e-05,
      "loss": 2.3831,
      "step": 1500
    },
    {
      "epoch": 0.23227195816028304,
      "grad_norm": 1.0639952421188354,
      "learning_rate": 9.226272881095217e-05,
      "loss": 2.4253,
      "step": 1510
    },
    {
      "epoch": 0.23381018304876172,
      "grad_norm": 0.911286473274231,
      "learning_rate": 9.221145464800287e-05,
      "loss": 2.3882,
      "step": 1520
    },
    {
      "epoch": 0.23534840793724043,
      "grad_norm": 1.0653918981552124,
      "learning_rate": 9.216018048505358e-05,
      "loss": 2.262,
      "step": 1530
    },
    {
      "epoch": 0.23688663282571912,
      "grad_norm": 0.775364339351654,
      "learning_rate": 9.21089063221043e-05,
      "loss": 2.3303,
      "step": 1540
    },
    {
      "epoch": 0.2384248577141978,
      "grad_norm": 0.9708721041679382,
      "learning_rate": 9.205763215915501e-05,
      "loss": 2.2572,
      "step": 1550
    },
    {
      "epoch": 0.23996308260267651,
      "grad_norm": 1.3037928342819214,
      "learning_rate": 9.200635799620572e-05,
      "loss": 2.3202,
      "step": 1560
    },
    {
      "epoch": 0.2415013074911552,
      "grad_norm": 0.8447539210319519,
      "learning_rate": 9.195508383325643e-05,
      "loss": 2.3549,
      "step": 1570
    },
    {
      "epoch": 0.2430395323796339,
      "grad_norm": 0.9687184691429138,
      "learning_rate": 9.190380967030714e-05,
      "loss": 2.3997,
      "step": 1580
    },
    {
      "epoch": 0.2445777572681126,
      "grad_norm": 1.085591197013855,
      "learning_rate": 9.185253550735785e-05,
      "loss": 2.3954,
      "step": 1590
    },
    {
      "epoch": 0.2461159821565913,
      "grad_norm": 0.7975506782531738,
      "learning_rate": 9.180126134440857e-05,
      "loss": 2.4023,
      "step": 1600
    },
    {
      "epoch": 0.24765420704507,
      "grad_norm": 0.8976469039916992,
      "learning_rate": 9.174998718145926e-05,
      "loss": 2.2802,
      "step": 1610
    },
    {
      "epoch": 0.24919243193354867,
      "grad_norm": 1.018182396888733,
      "learning_rate": 9.169871301850997e-05,
      "loss": 2.3703,
      "step": 1620
    },
    {
      "epoch": 0.2507306568220274,
      "grad_norm": 0.7566492557525635,
      "learning_rate": 9.164743885556068e-05,
      "loss": 2.2385,
      "step": 1630
    },
    {
      "epoch": 0.2522688817105061,
      "grad_norm": 1.6852009296417236,
      "learning_rate": 9.159616469261139e-05,
      "loss": 2.367,
      "step": 1640
    },
    {
      "epoch": 0.25380710659898476,
      "grad_norm": 1.081018090248108,
      "learning_rate": 9.154489052966211e-05,
      "loss": 2.2997,
      "step": 1650
    },
    {
      "epoch": 0.25534533148746347,
      "grad_norm": 1.0540295839309692,
      "learning_rate": 9.149361636671282e-05,
      "loss": 2.2617,
      "step": 1660
    },
    {
      "epoch": 0.2568835563759422,
      "grad_norm": 1.0538369417190552,
      "learning_rate": 9.144234220376353e-05,
      "loss": 2.3,
      "step": 1670
    },
    {
      "epoch": 0.25842178126442084,
      "grad_norm": 0.8911623358726501,
      "learning_rate": 9.139106804081424e-05,
      "loss": 2.3207,
      "step": 1680
    },
    {
      "epoch": 0.25996000615289955,
      "grad_norm": 1.278957724571228,
      "learning_rate": 9.133979387786494e-05,
      "loss": 2.3398,
      "step": 1690
    },
    {
      "epoch": 0.26149823104137826,
      "grad_norm": 1.0844378471374512,
      "learning_rate": 9.128851971491566e-05,
      "loss": 2.3718,
      "step": 1700
    },
    {
      "epoch": 0.26303645592985697,
      "grad_norm": 0.988380491733551,
      "learning_rate": 9.123724555196637e-05,
      "loss": 2.3238,
      "step": 1710
    },
    {
      "epoch": 0.26457468081833563,
      "grad_norm": 0.7687071561813354,
      "learning_rate": 9.118597138901708e-05,
      "loss": 2.3395,
      "step": 1720
    },
    {
      "epoch": 0.26611290570681434,
      "grad_norm": 1.2303543090820312,
      "learning_rate": 9.113469722606779e-05,
      "loss": 2.3137,
      "step": 1730
    },
    {
      "epoch": 0.26765113059529305,
      "grad_norm": 1.3194670677185059,
      "learning_rate": 9.10834230631185e-05,
      "loss": 2.2938,
      "step": 1740
    },
    {
      "epoch": 0.2691893554837717,
      "grad_norm": 0.8565366268157959,
      "learning_rate": 9.103214890016922e-05,
      "loss": 2.1883,
      "step": 1750
    },
    {
      "epoch": 0.2707275803722504,
      "grad_norm": 0.9481441974639893,
      "learning_rate": 9.098087473721993e-05,
      "loss": 2.2142,
      "step": 1760
    },
    {
      "epoch": 0.27226580526072913,
      "grad_norm": 1.1457215547561646,
      "learning_rate": 9.092960057427064e-05,
      "loss": 2.3523,
      "step": 1770
    },
    {
      "epoch": 0.2738040301492078,
      "grad_norm": 0.8666920065879822,
      "learning_rate": 9.087832641132133e-05,
      "loss": 2.333,
      "step": 1780
    },
    {
      "epoch": 0.2753422550376865,
      "grad_norm": 0.9516326189041138,
      "learning_rate": 9.082705224837204e-05,
      "loss": 2.3227,
      "step": 1790
    },
    {
      "epoch": 0.2768804799261652,
      "grad_norm": 1.125641942024231,
      "learning_rate": 9.077577808542276e-05,
      "loss": 2.2811,
      "step": 1800
    },
    {
      "epoch": 0.2784187048146439,
      "grad_norm": 0.7248914837837219,
      "learning_rate": 9.072450392247347e-05,
      "loss": 2.229,
      "step": 1810
    },
    {
      "epoch": 0.2799569297031226,
      "grad_norm": 1.1648125648498535,
      "learning_rate": 9.067322975952418e-05,
      "loss": 2.3461,
      "step": 1820
    },
    {
      "epoch": 0.2814951545916013,
      "grad_norm": 0.9306198954582214,
      "learning_rate": 9.062195559657489e-05,
      "loss": 2.4411,
      "step": 1830
    },
    {
      "epoch": 0.28303337948008,
      "grad_norm": 0.8632981777191162,
      "learning_rate": 9.05706814336256e-05,
      "loss": 2.3147,
      "step": 1840
    },
    {
      "epoch": 0.28457160436855866,
      "grad_norm": 1.0031105279922485,
      "learning_rate": 9.051940727067631e-05,
      "loss": 2.2313,
      "step": 1850
    },
    {
      "epoch": 0.2861098292570374,
      "grad_norm": 1.087646484375,
      "learning_rate": 9.046813310772702e-05,
      "loss": 2.3478,
      "step": 1860
    },
    {
      "epoch": 0.2876480541455161,
      "grad_norm": 1.4194533824920654,
      "learning_rate": 9.041685894477773e-05,
      "loss": 2.2992,
      "step": 1870
    },
    {
      "epoch": 0.2891862790339948,
      "grad_norm": 0.7619257569313049,
      "learning_rate": 9.036558478182844e-05,
      "loss": 2.2513,
      "step": 1880
    },
    {
      "epoch": 0.29072450392247345,
      "grad_norm": 0.8279052376747131,
      "learning_rate": 9.031431061887915e-05,
      "loss": 2.2539,
      "step": 1890
    },
    {
      "epoch": 0.29226272881095217,
      "grad_norm": 1.0974736213684082,
      "learning_rate": 9.026303645592987e-05,
      "loss": 2.2179,
      "step": 1900
    },
    {
      "epoch": 0.2938009536994309,
      "grad_norm": 0.9489269256591797,
      "learning_rate": 9.021176229298058e-05,
      "loss": 2.3707,
      "step": 1910
    },
    {
      "epoch": 0.29533917858790953,
      "grad_norm": 1.0058236122131348,
      "learning_rate": 9.016048813003129e-05,
      "loss": 2.2795,
      "step": 1920
    },
    {
      "epoch": 0.29687740347638825,
      "grad_norm": 0.9993000626564026,
      "learning_rate": 9.0109213967082e-05,
      "loss": 2.3638,
      "step": 1930
    },
    {
      "epoch": 0.29841562836486696,
      "grad_norm": 1.0579222440719604,
      "learning_rate": 9.00579398041327e-05,
      "loss": 2.2531,
      "step": 1940
    },
    {
      "epoch": 0.2999538532533456,
      "grad_norm": 0.7501667141914368,
      "learning_rate": 9.000666564118341e-05,
      "loss": 2.2578,
      "step": 1950
    },
    {
      "epoch": 0.3014920781418243,
      "grad_norm": 1.1398831605911255,
      "learning_rate": 8.995539147823412e-05,
      "loss": 2.2054,
      "step": 1960
    },
    {
      "epoch": 0.30303030303030304,
      "grad_norm": 0.9692484140396118,
      "learning_rate": 8.990411731528483e-05,
      "loss": 2.2561,
      "step": 1970
    },
    {
      "epoch": 0.30456852791878175,
      "grad_norm": 1.1439406871795654,
      "learning_rate": 8.985284315233554e-05,
      "loss": 2.317,
      "step": 1980
    },
    {
      "epoch": 0.3061067528072604,
      "grad_norm": 0.9182436466217041,
      "learning_rate": 8.980156898938625e-05,
      "loss": 2.3221,
      "step": 1990
    },
    {
      "epoch": 0.3076449776957391,
      "grad_norm": 0.8540138602256775,
      "learning_rate": 8.975029482643696e-05,
      "loss": 2.258,
      "step": 2000
    },
    {
      "epoch": 0.30918320258421783,
      "grad_norm": 0.9826604127883911,
      "learning_rate": 8.969902066348768e-05,
      "loss": 2.3034,
      "step": 2010
    },
    {
      "epoch": 0.3107214274726965,
      "grad_norm": 0.9897715449333191,
      "learning_rate": 8.964774650053839e-05,
      "loss": 2.2375,
      "step": 2020
    },
    {
      "epoch": 0.3122596523611752,
      "grad_norm": 0.9915783405303955,
      "learning_rate": 8.959647233758909e-05,
      "loss": 2.282,
      "step": 2030
    },
    {
      "epoch": 0.3137978772496539,
      "grad_norm": 0.7774962782859802,
      "learning_rate": 8.95451981746398e-05,
      "loss": 2.2192,
      "step": 2040
    },
    {
      "epoch": 0.31533610213813257,
      "grad_norm": 1.0849714279174805,
      "learning_rate": 8.94939240116905e-05,
      "loss": 2.1735,
      "step": 2050
    },
    {
      "epoch": 0.3168743270266113,
      "grad_norm": 1.3296504020690918,
      "learning_rate": 8.944264984874123e-05,
      "loss": 2.3533,
      "step": 2060
    },
    {
      "epoch": 0.31841255191509,
      "grad_norm": 0.8607456684112549,
      "learning_rate": 8.939137568579194e-05,
      "loss": 2.2663,
      "step": 2070
    },
    {
      "epoch": 0.3199507768035687,
      "grad_norm": 0.9673560857772827,
      "learning_rate": 8.934010152284265e-05,
      "loss": 2.2401,
      "step": 2080
    },
    {
      "epoch": 0.32148900169204736,
      "grad_norm": 0.9406920075416565,
      "learning_rate": 8.928882735989335e-05,
      "loss": 2.3318,
      "step": 2090
    },
    {
      "epoch": 0.3230272265805261,
      "grad_norm": 0.9379817247390747,
      "learning_rate": 8.923755319694406e-05,
      "loss": 2.2699,
      "step": 2100
    },
    {
      "epoch": 0.3245654514690048,
      "grad_norm": 0.9792314767837524,
      "learning_rate": 8.918627903399479e-05,
      "loss": 2.312,
      "step": 2110
    },
    {
      "epoch": 0.32610367635748344,
      "grad_norm": 1.2682822942733765,
      "learning_rate": 8.913500487104548e-05,
      "loss": 2.1895,
      "step": 2120
    },
    {
      "epoch": 0.32764190124596215,
      "grad_norm": 1.0079998970031738,
      "learning_rate": 8.908373070809619e-05,
      "loss": 2.2983,
      "step": 2130
    },
    {
      "epoch": 0.32918012613444086,
      "grad_norm": 0.9478371739387512,
      "learning_rate": 8.90324565451469e-05,
      "loss": 2.3464,
      "step": 2140
    },
    {
      "epoch": 0.3307183510229196,
      "grad_norm": 1.0139496326446533,
      "learning_rate": 8.898118238219761e-05,
      "loss": 2.3395,
      "step": 2150
    },
    {
      "epoch": 0.33225657591139823,
      "grad_norm": 0.8629897832870483,
      "learning_rate": 8.892990821924833e-05,
      "loss": 2.2077,
      "step": 2160
    },
    {
      "epoch": 0.33379480079987695,
      "grad_norm": 1.4620726108551025,
      "learning_rate": 8.887863405629904e-05,
      "loss": 2.3096,
      "step": 2170
    },
    {
      "epoch": 0.33533302568835566,
      "grad_norm": 0.9702004790306091,
      "learning_rate": 8.882735989334975e-05,
      "loss": 2.3519,
      "step": 2180
    },
    {
      "epoch": 0.3368712505768343,
      "grad_norm": 0.9932650327682495,
      "learning_rate": 8.877608573040046e-05,
      "loss": 2.3453,
      "step": 2190
    },
    {
      "epoch": 0.338409475465313,
      "grad_norm": 0.9327139258384705,
      "learning_rate": 8.872481156745115e-05,
      "loss": 2.2213,
      "step": 2200
    },
    {
      "epoch": 0.33994770035379174,
      "grad_norm": 0.8932101130485535,
      "learning_rate": 8.867353740450188e-05,
      "loss": 2.3821,
      "step": 2210
    },
    {
      "epoch": 0.3414859252422704,
      "grad_norm": 0.8775930404663086,
      "learning_rate": 8.862226324155259e-05,
      "loss": 2.3518,
      "step": 2220
    },
    {
      "epoch": 0.3430241501307491,
      "grad_norm": 1.0364453792572021,
      "learning_rate": 8.85709890786033e-05,
      "loss": 2.2383,
      "step": 2230
    },
    {
      "epoch": 0.3445623750192278,
      "grad_norm": 0.8616227507591248,
      "learning_rate": 8.8519714915654e-05,
      "loss": 2.2831,
      "step": 2240
    },
    {
      "epoch": 0.34610059990770653,
      "grad_norm": 1.1039588451385498,
      "learning_rate": 8.846844075270471e-05,
      "loss": 2.1571,
      "step": 2250
    },
    {
      "epoch": 0.3476388247961852,
      "grad_norm": 0.9709256887435913,
      "learning_rate": 8.841716658975544e-05,
      "loss": 2.4468,
      "step": 2260
    },
    {
      "epoch": 0.3491770496846639,
      "grad_norm": 1.002502679824829,
      "learning_rate": 8.836589242680614e-05,
      "loss": 2.3132,
      "step": 2270
    },
    {
      "epoch": 0.3507152745731426,
      "grad_norm": 0.9301533699035645,
      "learning_rate": 8.831461826385685e-05,
      "loss": 2.2703,
      "step": 2280
    },
    {
      "epoch": 0.35225349946162127,
      "grad_norm": 0.7622637748718262,
      "learning_rate": 8.826334410090755e-05,
      "loss": 2.3035,
      "step": 2290
    },
    {
      "epoch": 0.3537917243501,
      "grad_norm": 1.1477632522583008,
      "learning_rate": 8.821206993795826e-05,
      "loss": 2.3787,
      "step": 2300
    },
    {
      "epoch": 0.3553299492385787,
      "grad_norm": 0.7521834969520569,
      "learning_rate": 8.816079577500898e-05,
      "loss": 2.3054,
      "step": 2310
    },
    {
      "epoch": 0.3568681741270574,
      "grad_norm": 0.8684582114219666,
      "learning_rate": 8.810952161205969e-05,
      "loss": 2.2498,
      "step": 2320
    },
    {
      "epoch": 0.35840639901553606,
      "grad_norm": 0.8882172107696533,
      "learning_rate": 8.80582474491104e-05,
      "loss": 2.2009,
      "step": 2330
    },
    {
      "epoch": 0.35994462390401477,
      "grad_norm": 0.9389574527740479,
      "learning_rate": 8.800697328616111e-05,
      "loss": 2.2551,
      "step": 2340
    },
    {
      "epoch": 0.3614828487924935,
      "grad_norm": 0.7628786563873291,
      "learning_rate": 8.795569912321182e-05,
      "loss": 2.2782,
      "step": 2350
    },
    {
      "epoch": 0.36302107368097214,
      "grad_norm": 1.4449824094772339,
      "learning_rate": 8.790442496026253e-05,
      "loss": 2.3346,
      "step": 2360
    },
    {
      "epoch": 0.36455929856945085,
      "grad_norm": 0.8784567713737488,
      "learning_rate": 8.785315079731324e-05,
      "loss": 2.3712,
      "step": 2370
    },
    {
      "epoch": 0.36609752345792956,
      "grad_norm": 0.9509233236312866,
      "learning_rate": 8.780187663436394e-05,
      "loss": 2.2112,
      "step": 2380
    },
    {
      "epoch": 0.3676357483464082,
      "grad_norm": 0.7432436347007751,
      "learning_rate": 8.775060247141465e-05,
      "loss": 2.2662,
      "step": 2390
    },
    {
      "epoch": 0.36917397323488693,
      "grad_norm": 0.7712249755859375,
      "learning_rate": 8.769932830846536e-05,
      "loss": 2.1885,
      "step": 2400
    },
    {
      "epoch": 0.37071219812336564,
      "grad_norm": 0.9576478600502014,
      "learning_rate": 8.764805414551607e-05,
      "loss": 2.267,
      "step": 2410
    },
    {
      "epoch": 0.37225042301184436,
      "grad_norm": 0.8779605627059937,
      "learning_rate": 8.75967799825668e-05,
      "loss": 2.246,
      "step": 2420
    },
    {
      "epoch": 0.373788647900323,
      "grad_norm": 0.8408971428871155,
      "learning_rate": 8.75455058196175e-05,
      "loss": 2.2216,
      "step": 2430
    },
    {
      "epoch": 0.3753268727888017,
      "grad_norm": 0.9785459637641907,
      "learning_rate": 8.749423165666821e-05,
      "loss": 2.3978,
      "step": 2440
    },
    {
      "epoch": 0.37686509767728044,
      "grad_norm": 1.1419650316238403,
      "learning_rate": 8.744295749371892e-05,
      "loss": 2.3577,
      "step": 2450
    },
    {
      "epoch": 0.3784033225657591,
      "grad_norm": 0.8390716314315796,
      "learning_rate": 8.739168333076963e-05,
      "loss": 2.2553,
      "step": 2460
    },
    {
      "epoch": 0.3799415474542378,
      "grad_norm": 0.7990594506263733,
      "learning_rate": 8.734040916782034e-05,
      "loss": 2.3093,
      "step": 2470
    },
    {
      "epoch": 0.3814797723427165,
      "grad_norm": 0.9870525002479553,
      "learning_rate": 8.728913500487105e-05,
      "loss": 2.2984,
      "step": 2480
    },
    {
      "epoch": 0.3830179972311952,
      "grad_norm": 1.096959114074707,
      "learning_rate": 8.723786084192176e-05,
      "loss": 2.2643,
      "step": 2490
    },
    {
      "epoch": 0.3845562221196739,
      "grad_norm": 0.9146120548248291,
      "learning_rate": 8.718658667897247e-05,
      "loss": 2.3411,
      "step": 2500
    }
  ],
  "logging_steps": 10,
  "max_steps": 19503,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5275668971520000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
